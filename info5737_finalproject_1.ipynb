{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAO2dH+ch1hUnTCo4nYenk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kusalsai/Smart-Tutor-AI-AI-Driven-Personalized-Teaching-Support/blob/kusal_ayinala/info5737_finalproject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L59jokKC6G9U",
        "outputId": "3e8ada9e-49cf-449b-ff17-affb3a32eddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.25-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.25 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.25-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.26-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.16-py3-none-any.whl.metadata (902 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Downloading llama_index-0.12.25-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.25-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.26-py3-none-any.whl (16 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.16-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_cloud_services-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, typing-inspect, tiktoken, llama-cloud, dataclasses-json, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.16 llama-cloud-services-0.6.7 llama-index-0.12.25 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.25 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.9 llama-index-llms-openai-0.3.26 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.6 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.4.post1 marshmallow-3.26.1 mypy-extensions-1.0.0 pypdf-5.4.0 python-dotenv-1.0.1 striprtf-0.0.26 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install llama-index\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "from llama_index.core.node_parser import NodeParser # Import NodeParser\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "LKOEplmL6IR2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade python-pptx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjWWA4xT6KYQ",
        "outputId": "8dd511c2-d44b-4a8b-f80d-d6b46d66c88f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.2 python-pptx-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metadata\n"
      ],
      "metadata": {
        "id": "mnV07Wgd6fjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_text(file_path, text):\n",
        "    \"\"\"\n",
        "    Preprocesses the text depending on the file type:\n",
        "    - Removes punctuation for non-code files\n",
        "    - Leaves code files untouched\n",
        "    \"\"\"\n",
        "    # Define file extensions for code and text\n",
        "    code_extensions = {\".py\", \".java\", \".cpp\", \".js\", \".c\", \".cs\", \".html\", \".css\", \".php\", \".rb\"}\n",
        "    text_extensions = {\".pdf\", \".docx\", \".pptx\", \".txt\"}\n",
        "\n",
        "    # Check the file extension\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "    # If it's a text file, remove punctuation\n",
        "    if ext in text_extensions:\n",
        "        # Remove punctuation and unnecessary whitespace\n",
        "        text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # Keep words and spaces only\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "        text = re.sub(r\"\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b\", \"\", text)  # Remove dates like 3/3/2025\n",
        "        text = re.sub(r\"\\b\\d{5,}\\s\\d+\\b\", \"\", text)  # Remove page numbers like 332025 54\n",
        "    # If it's a code file (e.g., Python), leave the text as is\n",
        "    elif ext in code_extensions:\n",
        "        pass  # Do not modify code files\n",
        "\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "EHVc8lN06eNz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "\n",
        "# Assuming the PDF is directly in /content/\n",
        "# If it's in a subfolder, adjust the path accordingly\n",
        "document = SimpleDirectoryReader(\n",
        "    input_files=[\"/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf\"]\n",
        ").load_data()\n",
        "\n"
      ],
      "metadata": {
        "id": "zhMOvhns6NdG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply metadata to each document and preprocess text\n",
        "for doc in document:\n",
        "    doc.metadata = {\n",
        "        \"file_name\": doc.metadata.get(\"file_name\", \"\"),\n",
        "        \"file_path\": doc.metadata.get(\"file_path\", \"\"),\n",
        "        \"num_tokens\": len(doc.get_content().split()),  # Estimate token count\n",
        "        \"num_chars\": len(doc.get_content()),  # Count characters\n",
        "    }\n",
        "\n",
        "    # Preprocess the document's text and update content using set_content()\n",
        "    doc_text = doc.get_content()  # Use get_content() to retrieve text\n",
        "    processed_text = preprocess_text(doc.metadata[\"file_path\"], doc_text)\n",
        "    doc.set_content(processed_text)  # Use set_content() to update text\n"
      ],
      "metadata": {
        "id": "77H-zFkj6PrP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define chunk size and overlap\n",
        "CHUNK_SIZE = 512\n",
        "CHUNK_OVERLAP = 50  # Overlap between chunks\n",
        "PAD_CHAR = \" \"      # Padding character\n",
        "\n",
        "def exact_chunk_text(text, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):\n",
        "    \"\"\"\n",
        "    Splits text into fixed-size chunks of exactly `chunk_size` characters,\n",
        "    with optional overlap between chunks.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_len = len(text)\n",
        "\n",
        "    # Process text in chunks of exact size\n",
        "    while start < text_len:\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "\n",
        "        # If the chunk is smaller than `chunk_size`, pad it to ensure consistency\n",
        "        if len(chunk) < chunk_size:\n",
        "            chunk = chunk.ljust(chunk_size, PAD_CHAR)\n",
        "\n",
        "        chunks.append(chunk)\n",
        "\n",
        "        # Move the starting point of the next chunk by `chunk_size - overlap` to ensure overlap\n",
        "        start = end - overlap\n",
        "\n",
        "    return chunks\n",
        "\n",
        "class TextNode:\n",
        "    def __init__(self, text, id_):\n",
        "        self.text = text\n",
        "        self.id_ = id_\n",
        "\n",
        "# Process documents and create chunks with metadata\n",
        "nodes = []  # Store TextNode-like dictionary objects\n",
        "\n",
        "for doc in document:\n",
        "    text = doc.get_content().title()  # Convert to Title Case\n",
        "    text_chunks = exact_chunk_text(text)  # Exact chunking\n",
        "\n",
        "    for chunk in text_chunks:\n",
        "        metadata = {\n",
        "            \"file_name\": doc.metadata.get(\"file_name\", \"\"),\n",
        "            \"file_path\": doc.metadata.get(\"file_path\", \"\"),\n",
        "            \"num_tokens\": len(chunk.split()),  # Estimate token count\n",
        "            \"num_chars\": len(chunk),           # Number of characters\n",
        "        }\n",
        "        nodes.append({\"doc_id\": doc.doc_id, \"text\": chunk, \"metadata\": metadata})\n",
        "\n",
        "# Print processed chunks for debugging\n",
        "for i, doc in enumerate(nodes):\n",
        "    print(f\"\\nChunk {i + 1}:\")\n",
        "    print(f\"Document ID: {doc['doc_id']}\")\n",
        "    print(f\"Metadata: {doc['metadata']}\")\n",
        "    print(f\"Text: {doc['text'][:]}...\")  # Show only the first 100 characters for brevity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8hBxrlQ7Pe1",
        "outputId": "21a54cb9-e3c6-455a-bf88-dadbeec03883"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chunk 1:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 66, 'num_chars': 512}\n",
            "Text: Proceedings Of The 52Nd Annual Meeting Of The Association For Computational Linguistics Pages 12621273 Baltimore Maryland Usa June 2325 2014C2014 Association For Computational Linguistics Automatic Keyphrase Extraction A Survey Of The State Of The Art Kazi Saidul Hasanand Vincent Ng Human Language Technology Research Institute University Of Texas At Dallas Richardson Tx 750830688 Saidulvincehltutdallasedu Abstract While Automatic Keyphrase Extraction Has Been Examined Extensively Stateofthe Art Performance ...\n",
            "\n",
            "Chunk 2:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 85, 'num_chars': 512}\n",
            "Text: n Examined Extensively Stateofthe Art Performance On This Task Is Still Much Lower Than That On Many Core Natural Lan Guage Processing Tasks We Present A Sur Vey Of The State Of The Art In Automatic Keyphrase Extraction Examining The Major Sources Of Errors Made By Existing Systems And Discussing The Challenges Ahead 1 Introduction Automatic Keyphrase Extraction Concerns The Au Tomatic Selection Of Important And Topical Phrases From The Body Of A Document Turney 2000 In Other Words Its Goal Is To Extract A ...\n",
            "\n",
            "Chunk 3:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 90, 'num_chars': 512}\n",
            "Text: rney 2000 In Other Words Its Goal Is To Extract A Set Of Phrases That Are Related To The Main Topics Discussed In A Given Document Tomokiyo And Hurst 2003 Liu Et Al 2009B Ding Et Al 2011 Zhao Et Al 2011 Document Keyphrases Have Enabled Fast And Ac Curate Searching For A Given Document From A Large Text Collection And Have Exhibited Their Potential In Improving Many Natural Language Processing Nlp And Information Retrieval Ir Tasks Such As Text Summarization Zhang Et Al 2004 Text Categorization Hulth And Meg...\n",
            "\n",
            "Chunk 4:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 89, 'num_chars': 512}\n",
            "Text: Zhang Et Al 2004 Text Categorization Hulth And Megyesi 2006 Opin Ion Mining Berend 2011 And Document Index Ing Gutwin Et Al 1999 Owing To Its Importance Automatic Keyphrase Extraction Has Received A Lot Of Attention However The Task Is Far From Being Solved Stateoftheart Performance On Keyphrase Extraction Is Still Much Lower Than That On Many Core Nlp Tasks Liu Et Al 2010 Our Goal In This Paper Is To Survey The State Of The Art In Keyphrase Extraction Examining The Major Sources Of Errors Made By Existing ...\n",
            "\n",
            "Chunk 5:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: ning The Major Sources Of Errors Made By Existing Systems And Discussing The Challenges Ahead 2 Corpora Automatic Keyphrase Extraction Systems Have Been Evaluated On Corpora From A Variety Of Sources Ranging From Long Scientic Publications To Short Paper Abstracts And Email Messages Ta Ble 1 Presents A Listing Of The Corpora Grouped By Their Sources As Well As Their Statistics 1 There Are At Least Four Corpusrelated Factors That Affect The Difculty Of Keyphrase Extraction Length The Difculty Of The Task Inc...\n",
            "\n",
            "Chunk 6:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 85, 'num_chars': 512}\n",
            "Text: ase Extraction Length The Difculty Of The Task Increases With The Length Of The Input Document As Longer Doc Uments Yield More Candidate Keyphrases Ie Phrases That Are Eligible To Be Keyphrases See Sec Tion 31 For Instance Each Inspec Abstract Has On Average 10 Annotatorassigned Keyphrases And 34 Candidate Keyphrases In Contrast A Scientic Paper Typically Has At Least 10 Keyphrases And Hun Dreds Of Candidate Keyphrases Yielding A Much Bigger Search Space Hasan And Ng 2010 Conse Quently It Is Harder To Extra...\n",
            "\n",
            "Chunk 7:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: an And Ng 2010 Conse Quently It Is Harder To Extract Keyphrases From Sci Entic Papers Technical Reports And Meeting Tran Scripts Than Abstracts Emails And News Articles Structural Consistency In A Structured Doc Ument There Are Certain Locations Where A Keyphrase Is Most Likely To Appear For Instance Most Of A Scientic Papers Keyphrases Should Ap Pear In The Abstract And The Introduction While Structural Information Has Been Exploited To Ex Tract Keyphrases From Scientic Papers Eg Title Section Information ...\n",
            "\n",
            "Chunk 8:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: From Scientic Papers Eg Title Section Information Kim Et Al 2013 Web Pages Eg Metadata Yih Et Al 2006 And Chats Eg Dialogue Acts Kim And Baldwin 2012 It Is Most Useful When The Documents From A Source Exhibit Structural Similarity For This Reason Structural In Formation Is Likely To Facilitate Keyphrase Extrac Tion From Scientic Papers And Technical Reports Because Of Their Standard Format Ie Standard Sections Such As Abstract Introduction Conclusion Etc In Contrast The Lack Of Structural Consistency In Oth...\n",
            "\n",
            "Chunk 9:\n",
            "Document ID: 2606f7ce-2f6a-40cb-b854-c9c58deaab62\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 36, 'num_chars': 512}\n",
            "Text: Contrast The Lack Of Structural Consistency In Other Types Of Structured Documents Eg Web Pages Which Can Be Blogs Forums Or Reviews 1Many Of The Publicly Available Corpora Can Be Found In Httpgithubcomsnkimautomatickeyphraseextraction And Httpcodegooglecompmauiindexerdownloadslist 1262                                                                                                                                                                                                                                 ...\n",
            "\n",
            "Chunk 10:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: Source Datasetcontributor Statistics Documents Tokensdoc Keysdoc Paper Abstracts Inspec Hulth 2003 2000 200 10 Scientic Papers Nus Corpus Nguyen And Kan 2007 211 8K 11 Citeulikeorg Medelyan Et Al 2009 180 5 Semeval2010 Kim Et Al 2010B 284 5K 15 Technical Reports Nzdl Witten Et Al 1999 1800 News Articles Duc2001 Wan And Xiao 2008B 308 900 8 Reuters Corpus Hulth And Megyesi 2006  Web Pages Yih Et Al 2006 828 Hammouda Et Al 2005 312 500 Blogs Grineva Et Al 2009 252 1K 8 Meeting Transcripts Icsi Liu Et Al 2009A...\n",
            "\n",
            "Chunk 11:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 87, 'num_chars': 512}\n",
            "Text:  252 1K 8 Meeting Transcripts Icsi Liu Et Al 2009A 161 16K 4 Emails Enron Corpus Dredze Et Al 2008 14659 Live Chats Library Of Congress Kim And Baldwin 2012 15 10 Table 1 Evaluation Datasets Publicly Available Datasets Are Marked With An Asterisk May Render Structural Information Less Useful Topic Change An Observation Commonly Ex Ploited In Keyphrase Extraction From Scientic Ar Ticles And News Articles Is That Keyphrases Typically Appear Not Only At The Beginning Witten Et Al 1999 But Also At The End Medel...\n",
            "\n",
            "Chunk 12:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: inning Witten Et Al 1999 But Also At The End Medelyan Et Al 2009 Of A Document This Observation Does Not Neces Sarily Hold For Conversational Text Eg Meetings Chats However The Reason Is Simple In A Conver Sation The Topics Ie Its Talking Points Change As The Interaction Moves Forward In Time And So Do The Keyphrases Associated With A Topic One Way To Address This Complication Is To Detect A Topic Change In Conversational Text Kim And Baldwin 2012 However Topic Change Detection Is Not Al Ways Easy While The...\n",
            "\n",
            "Chunk 13:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: pic Change Detection Is Not Al Ways Easy While The Topics Listed In The Form Of An Agenda At The Beginning Of Formal Meeting Tran Scripts Can Be Exploited Such Clues Are Absent In Casual Conversations Eg Chats Topic Correlation Another Observation Com Monly Exploited In Keyphrase Extraction From Scientic Articles And News Articles Is That The Keyphrases In A Document Are Typically Related To Each Other Turney 2003 Mihalcea And Tarau 2004 However This Observation Does Not Nec Essarily Hold For Informal Text ...\n",
            "\n",
            "Chunk 14:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text: tion Does Not Nec Essarily Hold For Informal Text Eg Emails Chats Informal Meetings Personal Blogs Where People Can Talk About Any Number Of Potentially Uncorre Lated Topics The Presence Of Uncorrelated Topics Implies That It May No Longer Be Possible To Exploit Relatedness And Therefore Increases The Difculty Of Keyphrase Extraction 3 Keyphrase Extraction Approaches A Keyphrase Extraction System Typically Operates In Two Steps 1 Extracting A List Of Wordsphrases That Serve As Candidate Keyphrases Using Som...\n",
            "\n",
            "Chunk 15:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: rases That Serve As Candidate Keyphrases Using Some Heuristics Section 31 And 2 Determining Which Of These Candidate Keyphrases Are Correct Keyphrases Using Supervised Section 32 Or Un Supervised Section 33 Approaches 31 Selecting Candidate Words And Phrases As Noted Before A Set Of Phrases And Words Is Typically Extracted As Candidate Keyphrases Using Heuristic Rules These Rules Are Designed To Avoid Spurious Instances And Keep The Number Of Candi Dates To A Minimum Typical Heuristics Include 1 Using A Sto...\n",
            "\n",
            "Chunk 16:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 93, 'num_chars': 512}\n",
            "Text: A Minimum Typical Heuristics Include 1 Using A Stop Word List To Remove Stop Words Liu Et Al 2009B 2 Allowing Words With Certain Part Ofspeech Tags Eg Nouns Adjectives Verbs To Be Candidate Keywords Mihalcea And Tarau 2004 Wan And Xiao 2008B Liu Et Al 2009A 3 Al Lowing Ngrams That Appear In Wikipedia Article Titles To Be Candidates Grineva Et Al 2009 And 4 Extracting Ngrams Witten Et Al 1999 Hulth 2003 Medelyan Et Al 2009 Or Noun Phrases Barker And Cornacchia 2000 Wu Et Al 2005 That Satisfy Predened Lexicos...\n",
            "\n",
            "Chunk 17:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 86, 'num_chars': 512}\n",
            "Text: a 2000 Wu Et Al 2005 That Satisfy Predened Lexicosyntactic Patterns Nguyen And Phan 2009 Many Of These Heuristics Have Proven Effective With Their High Recall In Extracting Gold Keyphrases From Various Sources However For A Long Docu Ment The Resulting List Of Candidates Can Be Long Consequently Different Pruning Heuristics Have Been Designed To Prune Candidates That Are Un Likely To Be Keyphrases Huang Et Al 2006 Kumar And Srinathan 2008 Elbeltagy And Rafea 2009 You Et Al 2009 Newman Et Al 2012 32 Supervis...\n",
            "\n",
            "Chunk 18:\n",
            "Document ID: 46767d0f-fe09-4f49-8608-772a96138109\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 31, 'num_chars': 512}\n",
            "Text:  2009 You Et Al 2009 Newman Et Al 2012 32 Supervised Approaches Research On Supervised Approaches To Keyphrase Extraction Has Focused On Two Issues Task Refor Mulation And Feature Design 1263                                                                                                                                                                                                                                                                                                                                 ...\n",
            "\n",
            "Chunk 19:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: 321 Task Reformulation Early Supervised Approaches To Keyphrase Extrac Tion Recast This Task As A Binaryclassication Prob Lem Frank Et Al 1999 Turney 1999 Witten Et Al 1999 Turney 2000 The Goal Is To Train A Classier On Documents Annotated With Keyphrases To Determine Whether A Candidate Phrase Is A Keyphrase Keyphrases And Nonkeyphrases Are Used To Generate Positive And Negative Examples Respectively Different Learning Algorithms Have Been Used To Train This Classier Including Na Ve Bayes Frank Et Al 1999 ...\n",
            "\n",
            "Chunk 20:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 88, 'num_chars': 512}\n",
            "Text: s Classier Including Na Ve Bayes Frank Et Al 1999 Witten Et Al 1999 Decision Trees Turney 1999 Turney 2000 Bag Ging Hulth 2003 Boosting Hulth Et Al 2001 Maximum Entropy Yih Et Al 2006 Kim And Kan 2009 Multilayer Perceptron Lopez And Romary 2010 And Support Vector Machines Jiang Et Al 2009 Lopez And Romary 2010 Recasting Keyphrase Extraction As A Classica Tion Problem Has Its Weaknesses However Recall That The Goal Of Keyphrase Extraction Is To Identify The Most Representative Phrases For A Document In Other...\n",
            "\n",
            "Chunk 21:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 87, 'num_chars': 512}\n",
            "Text: ost Representative Phrases For A Document In Other Words If A Candidate Phrase C1 Is More Representative Than Another Candidate Phrasec2 C1 Should Be Preferred To C2 Note That A Binary Clas Sier Classies Each Candidate Keyphrase Indepen Dently Of The Others And Consequently It Does Not Allow Us To Determine Which Candidates Are Better Than The Others Hulth 2004 Wang And Li 2011 Motivated By This Observation Jiang Et Al 2009 Propose A Ranking Approach To Keyphrase Extraction Where The Goal Is To Learn A Rank...\n",
            "\n",
            "Chunk 22:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: hrase Extraction Where The Goal Is To Learn A Ranker To Rank Two Candidate Keyphrases This Pairwise Ranking Approach Therefore Introduces Competi Tion Between Candidate Keyphrases And Has Been Shown To Signicantly Outperform Kea Witten Et Al 1999 Frank Et Al 1999 A Popular Su Pervised Baseline That Adopts The Traditional Super Vised Classication Approach Song Et Al 2003 Kelleher And Luz 2005 322 Features The Features Commonly Used To Represent An In Stance For Supervised Keyphrase Extraction Can Be Broadly ...\n",
            "\n",
            "Chunk 23:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: or Supervised Keyphrase Extraction Can Be Broadly Divided Into Two Categories 3221 Withincollection Features Withincollection Features Are Computed Based Solely On The Training Documents These Features Can Be Further Divided Into Three Types Statistical Featuresare Computed Based On Sta Tistical Information Gathered From The Training Documents Three Such Features Have Been Exten Sively Used In Supervised Approaches The Rst One Tfidf Salton And Buckley 1988 Is Com Puted Based On Candidate Frequency In The Gi...\n",
            "\n",
            "Chunk 24:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 91, 'num_chars': 512}\n",
            "Text: s Com Puted Based On Candidate Frequency In The Given Text And Inverse Document Frequency Ie Number Of Other Documents Where The Candidate Appears2 The Second One The Distance Of A Phrase Is De Ned As The Number Of Words Preceding Its Rst Occurrence Normalized By The Number Of Words In The Document Its Usefulness Stems From The Fact That Keyphrases Tend To Appear Early In A Docu Ment The Third One Supervised Keyphraseness Encodes The Number Of Times A Phrase Appears As A Keyphrase In The Training Set This F...\n",
            "\n",
            "Chunk 25:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 94, 'num_chars': 512}\n",
            "Text:  Appears As A Keyphrase In The Training Set This Feature Is De Signed Based On The Assumption That A Phrase Fre Quently Tagged As A Keyphrase Is More Likely To Be A Keyphrase In An Unseen Document These Three Features Form The Feature Set Of Kea Witten Et Al 1999 Frank Et Al 1999 And Have Been Shown To Perform Consistently Well On Documents From Var Ious Sources Yih Et Al 2006 Kim Et Al 2013 Other Statistical Features Includephrase Length And Spread Ie The Number Of Words Between The Rst And Last Occurrence...\n",
            "\n",
            "Chunk 26:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 93, 'num_chars': 512}\n",
            "Text: umber Of Words Between The Rst And Last Occurrences Of A Phrase In The Document Structural Features Encode How Different In Stances Of A Candidate Keyphrase Are Located In Different Parts Of A Document A Phrase Is More Likely To Be A Keyphrase If It Appears In The Ab Stract Or Introduction Of A Paper Or In The Metadata Section Of A Web Page In Fact Features That En Code How Frequently A Candidate Keyphrase Occurs In Various Sections Of A Scientic Paper Eg In Troduction Conclusion Nguyen And Kan 2007 And Tho...\n",
            "\n",
            "Chunk 27:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text:  Troduction Conclusion Nguyen And Kan 2007 And Those That Encode The Location Of A Candidate Keyphrase In A Web Page Eg Whether It Appears In The Title Chen Et Al 2005 Yih Et Al 2006 Have Been Shown To Be Useful For The Task Syntactic Features Encode The Syntactic Pat Terns Of A Candidate Keyphrase For Example A Candidate Keyphrase Has Been Encoded As 1 A Pos Tag Sequence Which Denotes The Sequence Of Partofspeech Tags Assigned To Its Words And 2 A Sufx Sequence Which Is The Sequence Of Morphological Sufxes...\n",
            "\n",
            "Chunk 28:\n",
            "Document ID: 14fb8bdb-664b-4dc4-9552-099c433b631c\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 77, 'num_chars': 512}\n",
            "Text: ence Which Is The Sequence Of Morphological Sufxes Of Its Words Yih Et Al 2006 Nguyen And Kan 2007 Kim And Kan 2009 However Ablation Studies Conducted On Web Pages Yih Et Al 2006 And Scientic Articles 2A Tfidfbased Baseline Where Candidate Keyphrases Are Ranked And Selected According To Tfidf Has Been Widely Used By Both Supervised And Unsupervised Approaches Zhang Et Al 2005 Dredze Et Al 2008 Paukkeri Et Al 2008 Grineva Et Al 2009 1264                                                                        ...\n",
            "\n",
            "Chunk 29:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 79, 'num_chars': 512}\n",
            "Text: Kim And Kan 2009 Reveal That Syntactic Features Are Not Useful For Keyphrase Extraction In The Pres Ence Of Other Feature Types 3222 External Resourcebased Features External Resourcebased Features Are Computed Based On Information Gathered From Resources Other Than The Training Documents Such As Lex Ical Knowledge Bases Eg Wikipedia Or The Web With The Goal Of Improving Keyphrase Extrac Tion Performance By Exploiting External Knowl Edge Below We Give An Overview Of The Exter Nal Resourcebased Features That ...\n",
            "\n",
            "Chunk 30:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: view Of The Exter Nal Resourcebased Features That Have Proven Use Ful For Keyphrase Extraction Wikipediabased Keyphraseness Is Computed As A Candidates Document Frequency Multiplied By The Ratio Of The Number Of Wikipedia Articles Where The Candidate Appears As A Link To The Number Of Articles Where It Appears Medelyan Et Al 2009 This Feature Is Motivated By The Observation That A Candidate Is Likely To Be A Keyphrase If It Occurs Frequently As A Link In Wikipedia Unlike Super Vised Keyphraseness Wikipediab...\n",
            "\n",
            "Chunk 31:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: ipedia Unlike Super Vised Keyphraseness Wikipediabased Keyphrase Ness Can Be Computed Without Using Documents Annotated With Keyphrases And Can Work Even If There Is A Mismatch Between The Training Domain And The Test Domain Yih Et Al 2006 Employ A Feature That En Codes Whether A Candidate Keyphrase Appears In The Query Log Of A Search Engine Exploiting The Ob Servation That A Candidate Is Potentially Important If It Was Used As A Search Query Terminological Databases Have Been Similarly Exploited To Encode...\n",
            "\n",
            "Chunk 32:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 76, 'num_chars': 512}\n",
            "Text:  Databases Have Been Similarly Exploited To Encode The Salience Of Candidate Keyphrases In Scientic Papers Lopez And Romary 2010 While The Aforementioned External Resource Based Features Attempt To Encode How Salient A Candidate Keyphrase Is Turney 2003 Proposes Features That Encode The Semantic Relatedness Be Tween Two Candidate Keyphrases Noting That Can Didate Keyphrases That Are Not Semantically Re Lated To The Predicted Keyphrases Are Unlikely To Be Keyphrases In Technical Reports Turney Em Ploys Coher...\n",
            "\n",
            "Chunk 33:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: phrases In Technical Reports Turney Em Ploys Coherence Features To Identify Such Can Didate Keyphrases Semantic Relatedness Is En Coded In The Coherence Features As Two Candidate Keyphrases Pointwise Mutual Information Which Turney Computes By Using The Web As A Corpus 33 Unsupervised Approaches Existing Unsupervised Approaches To Keyphrase Extraction Can Be Categorized Into Four Groups 331 Graphbased Ranking Intuitively Keyphrase Extraction Is About Nding The Important Words And Phrases From A Docu Ment Tr...\n",
            "\n",
            "Chunk 34:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: he Important Words And Phrases From A Docu Ment Traditionally The Importance Of A Candi Date Has Often Been Dened In Terms Of How Related It Is To Other Candidates In The Document Infor Mally A Candidate Is Important If It Is Related To 1 A Large Number Of Candidates And 2 Candidates That Are Important Researchers Have Computedre Latedness Between Candidates Using Cooccurrence Counts Mihalcea And Tarau 2004 Matsuo And Ishizuka 2004 And Semantic Relatedness Grineva Et Al 2009 And Represented The Relatedness ...\n",
            "\n",
            "Chunk 35:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 91, 'num_chars': 512}\n",
            "Text: rineva Et Al 2009 And Represented The Relatedness In Formation Collected From A Document As A Graph Mihalcea And Tarau 2004 Wan And Xiao 2008A Wan And Xiao 2008B Bougouin Et Al 2013 The Basic Idea Behind A Graphbased Approach Is To Build A Graph From The Input Document And Rank Its Nodes According To Their Importance Us Ing A Graphbased Ranking Method Eg Brin And Page 1998 Each Node Of The Graph Corresponds To A Candidate Keyphrase From The Document And An Edge Connects Two Related Candidates The Edge Weigh...\n",
            "\n",
            "Chunk 36:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: dge Connects Two Related Candidates The Edge Weight Is Proportional To The Syntactic Andor Semantic Relevance Between The Connected Candi Dates For Each Node Each Of Its Edges Is Treated As A Vote From The Other Node Connected By The Edge A Nodes Score In The Graph Is Dened Recur Sively In Terms Of The Edges It Has And The Scores Of The Neighboring Nodes The Topranked Candidates From The Graph Are Then Selected As Keyphrases For The Input Document Textrank Mihalcea And Ta Rau 2004 Is One Of The Most Wellkno...\n",
            "\n",
            "Chunk 37:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: ihalcea And Ta Rau 2004 Is One Of The Most Wellknown Graph Based Approaches To Keyphrase Extraction This Instantiation Of A Graphbased Approach Overlooks An Important Aspect Of Keyphrase Ex Traction However A Set Of Keyphrases For A Doc Ument Should Ideally Cover The Main Topics Dis Cussed In It But This Instantiation Does Not Guaran Tee That All The Main Topics Will Be Represented By The Extracted Keyphrases Despite This Weakness A Graphbased Representation Of Text Was Adopted By Many Approaches That Propo...\n",
            "\n",
            "Chunk 38:\n",
            "Document ID: accac97c-e823-41b1-86ac-d5c5751503e2\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 67, 'num_chars': 512}\n",
            "Text:  Of Text Was Adopted By Many Approaches That Propose Different Ways Of Computing The Similarity Between Two Candidates 332 Topicbased Clustering Another Unsupervised Approach To Keyphrase Extraction Involves Grouping The Candidate Keyphrases In A Document Into Topics Such That Each Topic Is Composed Of All And Only Those Candidate Keyphrases That Are Related To That Topic Grineva Et Al 2009 Liu Et Al 2009B Liu Et 1265                                                                                           ...\n",
            "\n",
            "Chunk 39:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 89, 'num_chars': 512}\n",
            "Text: Al 2010 There Are Several Motivations Behind This Topicbased Clustering Approach First A Keyphrase Should Ideally Be Relevant To One Or More Main Topics Discussed In A Document Liu Et Al 2010 Liu Et Al 2012 Second The Extracted Keyphrases Should Be Comprehensive In The Sense That They Should Cover All The Main Topics In A Document Liu Et Al 2009B Liu Et Al 2010 Liu Et Al 2012 Below We Examine Three Representative Systems That Adopt This Approach Keycluster Liu Et Al 2009B Adopt A Clusteringbased Approach He...\n",
            "\n",
            "Chunk 40:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 77, 'num_chars': 512}\n",
            "Text: iu Et Al 2009B Adopt A Clusteringbased Approach Henceforth Keyclus Ter That Clusters Semantically Similar Candidates Using Wikipedia And Cooccurrencebased Statis Tics The Underlying Hypothesis Is That Each Of These Clusters Corresponds To A Topic Covered In The Document And Selecting The Candidates Close To The Centroid Of Each Cluster As Keyphrases Ensures That The Resulting Set Of Keyphrases Covers All The Topics Of The Document While Empirical Results Show That Keycluster Performs Better Than Both Textra...\n",
            "\n",
            "Chunk 41:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 82, 'num_chars': 512}\n",
            "Text: w That Keycluster Performs Better Than Both Textrank And Hulths 2003 Supervised System Keycluster Has A Poten Tial Drawback By Extracting Keyphrases From Each Topic Cluster It Essentially Gives Each Topic Equal Importance In Practice However There Could Be Topics That Are Not Important And These Topics Should Not Have Keyphrases Representing Them Topical Pagerank Tpr Liu Et Al 2010 Pro Pose Tpr An Approach That Overcomes The Afore Mentioned Weakness Of Keycluster It Runs Tex Trank Multiple Times For A Docum...\n",
            "\n",
            "Chunk 42:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: uster It Runs Tex Trank Multiple Times For A Document Once For Each Of Its Topics Induced By A Latent Dirichlet Al Location Blei Et Al 2003 By Running Textrank Once For Each Topic Tpr Ensures That The Extracted Keyphrases Cover The Main Topics Of The Document The Nal Score Of A Candidate Is Computed As The Sum Of Its Scores For Each Of The Topics Weighted By The Probability Of That Topic In That Document Hence Unlike Keycluster Candidates Belonging To A Less Probable Topic Are Given Less Importance Tpr Perf...\n",
            "\n",
            "Chunk 43:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text:  Probable Topic Are Given Less Importance Tpr Performs Signicantly Better Than Both Tfidf And Textrank On The Duc2001 And Inspec Datasets Tprs Superior Performance Strength Ens The Hypothesis Of Using Topic Clustering For Keyphrase Extraction However Though Tpr Is Conceptually Better Than Keycluster Liu Et Al Did Not Compare Tpr Against Keycluster Communitycluster Grineva Et Al 2009 Pro Pose Communitycluster A Variant Of The Topic Clustering Approach To Keyphrase Extraction Like Tpr Communitycluster Gives M...\n",
            "\n",
            "Chunk 44:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 80, 'num_chars': 512}\n",
            "Text: hrase Extraction Like Tpr Communitycluster Gives More Weight To More Important Topics But Unlike Tpr It Extracts All Candidate Keyphrases From An Important Topic Assuming That A Candidate That Receives Little Focus In The Text Should Still Be Extracted As A Keyphrase As Long As It Is Related To An Important Topic Com Munitycluster Yields Much Better Recall Without Losing Precision Than Extractors Such As Tfidf Textrank And The Yahoo Term Extractor 333 Simultaneous Learning Since Keyphrases Represent A Dense...\n",
            "\n",
            "Chunk 45:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: aneous Learning Since Keyphrases Represent A Dense Summary Of A Document Researchers Hypothesized That Text Sum Marization And Keyphrase Extraction Can Poten Tially Benet From Each Other If These Tasks Are Per Formed Simultaneously Zha 2002 Proposes The Rst Graphbased Approach For Simultaneous Sum Marization And Keyphrase Extraction Motivated By A Key Observation A Sentence Is Important If It Con Tains Important Words And Important Words Ap Pear In Important Sentences Wan Et Al 2007 Ex Tend Zhas Work By Add...\n",
            "\n",
            "Chunk 46:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 94, 'num_chars': 512}\n",
            "Text:  Sentences Wan Et Al 2007 Ex Tend Zhas Work By Adding Two Assumptions 1 An Important Sentence Is Connected To Other Im Portant Sentences And 2 An Important Word Is Linked To Other Important Words A Textranklike Assumption Based On These Assumptions Wan Et Al 2007 Build Three Graphs To Capture The Asso Ciation Between The Sentences S And The Words W In An Input Document Namely A Ss Graph A Bipartite Sw Graph And A Ww Graph The Weight Of An Edge Connecting Two Sentence Nodes In A Ss Graph Corresponds To Their...\n",
            "\n",
            "Chunk 47:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 88, 'num_chars': 512}\n",
            "Text:  Sentence Nodes In A Ss Graph Corresponds To Their Content Simi Larity An Edge Weight In A Sw Graph Denotes The Words Importance In The Sentence It Appears Fi Nally An Edge Weight In A Ww Graph Denotes The Cooccurrence Or Knowledgebased Similarity Be Tween The Two Connected Words Once The Graphs Are Constructed For An Input Document An Itera Tive Reinforcement Algorithm Is Applied To Assign Scores To Each Sentence And Word The Topscored Words Are Used To Form Keyphrases The Main Advantage Of This Approach I...\n",
            "\n",
            "Chunk 48:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 91, 'num_chars': 512}\n",
            "Text: m Keyphrases The Main Advantage Of This Approach Is That It Combines The Strengths Of Both Zhas Approach Ie Bipartite Sw Graphs And Textrank Ie W W Graphs And Performs Better Than Both Of Them However It Has A Weakness Like Textrank It Does Not Ensure That The Extracted Keyphrases Will Cover All The Main Topics To Address This Problem One Can Employ A Topic Clustering Algorithm On The W W Graph To Produce The Topic Clusters And Then En Sure That Keyphrases Are Chosen From Every Main Topic Cluster 1266      ...\n",
            "\n",
            "Chunk 49:\n",
            "Document ID: 076e076c-1227-4eb3-9c58-9d1cc7c85509\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 8, 'num_chars': 512}\n",
            "Text: re Chosen From Every Main Topic Cluster 1266                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...\n",
            "\n",
            "Chunk 50:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: 334 Language Modeling Many Existing Approaches Have A Separate Heuris Tic Module For Extracting Candidate Keyphrases Prior To Keyphrase Rankingextraction In Contrast Tomokiyo And Hurst 2003 Propose An Approach Henceforth Lma That Combines These Two Steps Lma Scores A Candidate Keyphrase Based On Two Features Namely Phraseness Ie The Ex Tent To Which A Word Sequence Can Be Treated As A Phrase And Informativeness Ie The Extent To Which A Word Sequence Captures The Central Idea Of The Document It Appears In In...\n",
            "\n",
            "Chunk 51:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 89, 'num_chars': 512}\n",
            "Text:  The Central Idea Of The Document It Appears In Intuitively A Phrase That Has High Scores For Phraseness And Informa Tiveness Is Likely To Be A Keyphrase These Feature Values Are Estimated Using Language Models Lms Trained On A Foreground Corpus And A Background Corpus The Foreground Corpus Is Composed Of The Set Of Documents From Which Keyphrases Are To Be Extracted The Background Corpus Is A Large Corpus That Encodes General Knowledge About The World Eg The Web A Unigram Lm And An N Gram Lm Are Constructe...\n",
            "\n",
            "Chunk 52:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 94, 'num_chars': 512}\n",
            "Text: e Web A Unigram Lm And An N Gram Lm Are Constructed For Each Of These Two Corpora Phraseness Dened Using The Foreground Lm Is Calculated As The Loss Of Information In Curred As A Result Of Assuming A Unigram Lm Ie Conditional Independence Among The Words Of The Phrase Instead Of An Ngram Lm Ie The Phrase Is Drawn From An Ngram Lm Informativeness Is Computed As The Loss That Results Because Of The Assumption That The Candidate Is Sampled From The Background Lm Rather Than The Foreground Lm The Loss Values Ar...\n",
            "\n",
            "Chunk 53:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: m Rather Than The Foreground Lm The Loss Values Are Computed Using Kullback Leibler Divergence Candidates Are Ranked Accord Ing To The Sum Of These Two Feature Values In Sum Lma Uses A Language Model Rather Than Heuristics To Identify Phrases And Relies On The Lan Guage Model Trained On The Background Corpus To Determine How Unique A Candidate Keyphrase Is To The Domain Represented By The Foreground Cor Pus The More Unique It Is To The Foregrounds Do Main The More Likely It Is A Keyphrase For That Do Main W...\n",
            "\n",
            "Chunk 54:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: e More Likely It Is A Keyphrase For That Do Main While The Use Of Language Models To Iden Tify Phrases Cannot Be Considered A Major Strength Of This Approach Because Heuristics Can Identify Phrases Fairly Reliably The Use Of A Background Corpus To Identify Candidates That Are Unique To The Foregrounds Domain Is A Unique Aspect Of This Ap Proach We Believe That This Idea Deserves Further Investigation As It Would Allow Us To Discover A Keyphrase That Is Unique To The Foregrounds Do Main But May Have A Low Tf...\n",
            "\n",
            "Chunk 55:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 86, 'num_chars': 512}\n",
            "Text: e To The Foregrounds Do Main But May Have A Low Tfidf Value 4 Evaluation In This Section We Describe Metrics For Evaluating Keyphrase Extraction Systems As Well As Stateof Theart Results On Commonlyused Datasets 41 Evaluation Metrics Designing Evaluation Metrics For Keyphrase Ex Traction Is By No Means An Easy Task To Score The Output Of A Keyphrase Extraction System The Typical Approach Which Is Also Adopted By The Semeval2010 Shared Task On Keyphrase Extrac Tion Is 1 To Create A Mapping Between The Keyphr...\n",
            "\n",
            "Chunk 56:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: c Tion Is 1 To Create A Mapping Between The Keyphrases In The Gold Standard And Those In The System Output Using Exact Match And Then 2 Score The Output Using Evaluation Metrics Such As Precision P Recall R And Fscore F Conceivably Exact Match Is An Overly Strict Con Dition Considering A Predicted Keyphrase Incor Rect Even If It Is A Variant Of A Gold Keyphrase For Instance Given The Gold Keyphrase Neural Network Exact Match Will Consider A Predicted Phrase Incorrect Even If It Is An Expanded Version Of The...\n",
            "\n",
            "Chunk 57:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: Incorrect Even If It Is An Expanded Version Of The Gold Keyphrase Articial Neural Network Or One Of Its Morphological Neural Networks Or Lexical Neural Net Variants While Morphologi Cal Variations Can Be Handled Using A Stemmer El Beltagy And Rafea 2009 Other Variations May Not Be Handled Easily And Reliably Human Evaluation Has Been Suggested As A Pos Sibility Matsuo And Ishizuka 2004 But It Is Time Consuming And Expensive For This Reason Re Searchers Have Experimented With Two Types Of Automatic Evaluatio...\n",
            "\n",
            "Chunk 58:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: Experimented With Two Types Of Automatic Evaluation Metrics The Rst Type Of Metrics Addresses The Problem With Exact Match These Metrics Reward A Partial Match Between A Predicted Keyphrase And A Gold Keyphrase Ie Overlapping Ngrams And Are Commonly Used In Machine Translation Mt And Summarization Evaluations They Include Bleu Meteor Nist And Rouge Nevertheless Experiments Show That These Mt Metrics Only Offer A Partial Solution To Problem With Exact Match They Can Only Detect A Subset Of The Nearmisses Kim...\n",
            "\n",
            "Chunk 59:\n",
            "Document ID: 80598975-b654-483f-a2ed-e0b55e9f37eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 85, 'num_chars': 512}\n",
            "Text: hey Can Only Detect A Subset Of The Nearmisses Kim Et Al 2010A The Second Type Of Metrics Focuses On How A System Ranks Its Predictions Given That Two Sys Tems A And B Have The Same Number Of Correct Predictions Binary Preference Measure Bpref And Mean Reciprocal Rank Mrr Liu Et Al 2010 Will Award More Credit To A Than To B If The Ranks Of The Correct Predictions In As Output Are Higher Than Those In Bs Output Rprecision Rp Is An 1267                                                                          ...\n",
            "\n",
            "Chunk 60:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 94, 'num_chars': 512}\n",
            "Text: Ir Metric That Focuses On Ranking Given A Docu Ment With N Gold Keyphrases It Computes The Pre Cision Of A System Over Its N Highestranked Can Didates Zesch And Gurevych 2009 The Motiva Tion Behind The Design Of Rp Is Simple A System Will Achieve A Perfect Rp Value If It Ranks All The Keyphrases Above The Nonkeyphrases 42 The State Of The Art Table 2 Lists The Best Scores On Some Popular Evalu Ation Datasets And The Corresponding Systems For Example The Best Fscores On The Inspec Test Set The Duc2001 Datase...\n",
            "\n",
            "Chunk 61:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text:  Fscores On The Inspec Test Set The Duc2001 Dataset And The Semeval2010 Test Set Are 457 317 And 275 Respectively3 Two Points Deserve Mention First Fscores De Crease As Document Length Increases These Re Sults Are Consistent With The Observation We Made In Section 2 That It Is More Difcult To Extract Keyphrases Correctly From Longer Documents Sec Ond Recent Unsupervised Approaches Have Rivaled Their Supervised Counterparts In Performance Mi Halcea And Tarau 2004 Elbeltagy And Rafea 2009 Liu Et Al 2009B For ...\n",
            "\n",
            "Chunk 62:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: 2004 Elbeltagy And Rafea 2009 Liu Et Al 2009B For Example Kpminer Elbeltagy And Rafea 2010 An Unsupervised System Ranked Third In The Semeval2010 Shared Task With An Fscore Of 252 Which Is Comparable To The Best Supervised System Scoring 275 5 Analysis With The Goal Of Providing Directions For Future Work We Identify The Errors Commonly Made By Stateoftheart Keyphrase Extractors Below 51 Error Analysis Although A Few Researchers Have Presented A Sam Ple Of Their Systems Output And The Corresponding Gold Key...\n",
            "\n",
            "Chunk 63:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: heir Systems Output And The Corresponding Gold Keyphrases To Show The Differences Between Them Witten Et Al 1999 Nguyen And Kan 2007 Medelyan Et Al 2009 A Systematic Analysis Of The Major Types Of Errors Made By Stateoftheart Keyphrase Extraction Systems Is Missing To Ll This Gap We Ran Four Keyphrase Extrac Tion Systems On Four Commonlyused Datasets Of Varying Sources Includinginspec Abstracts Hulth 2003 Duc2001 News Articles Over 2001 Sci Entic Papers Kim Et Al 2010B And Meeting Transcripts Liu Et Al 2009...\n",
            "\n",
            "Chunk 64:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 90, 'num_chars': 512}\n",
            "Text: Et Al 2010B And Meeting Transcripts Liu Et Al 2009A Specically We Ran Domly Selected 25 Documents From Each Of These 3A More Detailed Analysis Of The Results Of The Semeval 2010 Shared Task And The Approaches Adopted By The Partici Pating Systems Can Be Found In Kim Et Al 2013 Dataset Approach And System Supervised Score P R F Abstracts Inspec Topic Clustering Liu Et Al 2009B 350 660 457 Blogs Topic Community Detection Grineva Et Al 2009 351 615 447 News Duc 2001 Graphbased Ranking For Extended Neighborhood...\n",
            "\n",
            "Chunk 65:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 85, 'num_chars': 512}\n",
            "Text:  2001 Graphbased Ranking For Extended Neighborhood Wan And Xiao 2008B 288 354 317 Papers Semeval 2010 Statistical Semantic And Distributional Features Lopez And Romary 2010 272 278 275 Table 2 Best Scores Achieved On Various Datasets Four Datasets And Manually Analyzed The Output Of The Four Systems Including Tfidf The Most Fre Quently Used Baseline As Well As Three Stateofthe Art Keyphrase Extractors Of Which Two Are Unsu Pervised Wan And Xiao 2008B Liu Et Al 2009B And One Is Supervised Medelyan Et Al 2009...\n",
            "\n",
            "Chunk 66:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: Al 2009B And One Is Supervised Medelyan Et Al 2009 Our Analysis Reveals That The Errors Fall Into Four Major Types Each Of Which Contributes Signi Cantly To The Overall Errors Made By The Four Sys Tems Despite The Fact That The Contribution Of Each Of These Error Types Varies From System To System Moreover We Do Not Observe Any Signicant Dif Ference Between The Types Of Errors Made By The Four Systems Other Than The Fact That The Super Vised System Has The Expected Tendency To Predict Keyphrases Seen In The...\n",
            "\n",
            "Chunk 67:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: xpected Tendency To Predict Keyphrases Seen In The Training Data Below We Describe These Four Major Types Of Errors Overgeneration Errorsare A Major Type Of Pre Cision Error Contributing To 2837 Of The Overall Error Overgeneration Errors Occur When A System Correctly Predicts A Candidate As A Keyphrase Be Cause It Contains A Word That Appears Frequently In The Associated Document But At The Same Time Er Roneously Outputs Other Candidates As Keyphrases Because They Contain The Same Word Recall That For Many ...\n",
            "\n",
            "Chunk 68:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 95, 'num_chars': 512}\n",
            "Text: e They Contain The Same Word Recall That For Many Systems It Is Not Easy To Reject A Non Keyphrase Containing A Word With A High Term Fre Quency Many Unsupervised Systems Score A Can Didate By Summing The Score Of Each Of Its Compo Nent Words And Many Supervised Systems Use Un Igrams As Features To Represent A Candidate To Be More Concrete Consider The News Article On Athlete Ben Johnson In Figure 1 Where The Keyphrases Are Boldfaced As We Can See The Word Olympics Has A Signicant Presence In The Document C...\n",
            "\n",
            "Chunk 69:\n",
            "Document ID: 1683eb45-9ed4-4f75-a16f-435a5dcd248e\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 42, 'num_chars': 512}\n",
            "Text: lympics Has A Signicant Presence In The Document Con Sequently Many Systems Not Only Correctly Predict Olympics As A Keyphrase But Also Erroneously Pre Dict Olympic Movement As A Keyphrase Yielding Overgeneration Errors Infrequency Errors Are A Major Type Of Re 1268                                                                                                                                                                                                                                                      ...\n",
            "\n",
            "Chunk 70:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 89, 'num_chars': 512}\n",
            "Text: Canadian Ben Johnson Left The Olympics Today In A Complete State Of Shock Accused Of Cheating With Drugs In The Worlds Fastest 100Meter Dash And Stripped Of His Gold Medal The Prize Went To American Carl Lewis Many Athletes Accepted The Accusation That John Son Used A Musclebuilding But Dangerous And Illegal An Abolic Steroid Called Stanozolol As Conrmation Of What They Said They Know Has Been Going On In Track And Eld Two Tests Of Johnsons Urine Sample Proved Positive And His Denials Of Drug Use Were Rejec...\n",
            "\n",
            "Chunk 71:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 85, 'num_chars': 512}\n",
            "Text: ed Positive And His Denials Of Drug Use Were Rejected Today This Is A Blow For The Olympic Games And The Olympic Move Ment Said International Olympic Committee President Juan Antonio Samaranch Figure 1 A News Article On Ben Johnson From The Duc2001 Dataset The Keyphrases Are Boldfaced Call Error Contributing To 2427 Of The Overall Error Infrequency Errors Occur When A System Fails To Identify A Keyphrase Owing To Its Infre Quent Presence In The Associated Document Liu Et Al 2011 Handling Infrequency Errors ...\n",
            "\n",
            "Chunk 72:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text: cument Liu Et Al 2011 Handling Infrequency Errors Is A Challenge Because Stateoftheart Keyphrase Ex Tractors Rarely Predict Candidates That Appear Only Once Or Twice In A Document In The Ben Johnson Example Many Keyphrase Extractors Fail To Iden Tify 100Meter Dash And Gold Medal As Keyphrases Resulting In Infrequency Errors Redundancy Errorsare A Type Of Precision Er Ror Contributing To 812 Of The Overall Error Re Dundancy Errors Occur When A System Correctly Identies A Candidate As A Keyphrase But At The S...\n",
            "\n",
            "Chunk 73:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 87, 'num_chars': 512}\n",
            "Text: y Identies A Candidate As A Keyphrase But At The Same Time Outputs A Semantically Equivalent Can Didate Eg Its Alias As A Keyphrase This Type Of Error Can Be Attributed To A Systems Failure To Determine That Two Candidates Are Semantically Equivalent Nevertheless Some Researchers May Argue That A System Should Not Be Penalized For Re Dundancy Errors Because The Extracted Candidates Are In Fact Keyphrases In Our Example Olympics And Olympic Games Refer To The Same Concept So A System That Predicts Both Of Th...\n",
            "\n",
            "Chunk 74:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 86, 'num_chars': 512}\n",
            "Text:  Same Concept So A System That Predicts Both Of Them As Keyphrases Commits A Redundancy Error Evaluation Errorsare A Type Of Recall Error Con Tributing To 710 Of The Overall Error An Evalu Ation Error Occurs When A System Outputs A Can Didate That Is Semantically Equivalent To A Gold Keyphrase But Is Considered Erroneous By A Scor Ing Program Because Of Its Failure To Recognize That The Predicted Phrase And The Corresponding Gold Keyphrase Are Semantically Equivalent In Other Words An Evaluation Error Is No...\n",
            "\n",
            "Chunk 75:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 87, 'num_chars': 512}\n",
            "Text: quivalent In Other Words An Evaluation Error Is Not An Error Made By A Keyphrase Extractor But An Error Due To The Naivety Of A Scoring Program In Our Exam Ple While Olympics And Olympic Games Refer To The Same Concept Only The Former Is Annotated As Keyphrase Hence An Evaluation Error Occurs If A System Predicts Olympic Games But Not Olympics As A Keyphrase And The Scoring Program Fails To Identify Them As Semantically Equivalent 52 Recommendations We Recommend That Background Knowledge Be Extracted From E...\n",
            "\n",
            "Chunk 76:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 81, 'num_chars': 512}\n",
            "Text: mend That Background Knowledge Be Extracted From External Lexical Databases Eg Y Ago2 Suchanek Et Al 2007 Freebase Bol Lacker Et Al 2008 Babelnet Navigli And Ponzetto 2012 To Address The Four Types Of Er Rors Discussed Above First We Discuss Howredundancy Errorscould Be Addressed By Using The Background Knowledge Extracted From External Databases Note That If We Can Identify Semantically Equivalent Candidates Then We Can Reduce Redundancy Errors The Ques Tion Then Is Can Background Knowledge Be Used To Help...\n",
            "\n",
            "Chunk 77:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 89, 'num_chars': 512}\n",
            "Text: n Then Is Can Background Knowledge Be Used To Help Us Identify Semantically Equivalent Candi Dates To Answer This Question Note That Freebase For Instance Has Over 40 Million Topics Ie Real World Entities Such As People Places And Things From Over 70 Domains Eg Music Business Ed Ucation Hence Before A System Outputs A Set Of Candidates As Keyphrases It Can Use Freebase To Determine Whether Any Of Them Is Mapped To The Same Freebase Topic Referring Back To Our Run Ning Example Both Olympics And Olympic Games...\n",
            "\n",
            "Chunk 78:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 86, 'num_chars': 512}\n",
            "Text: r Run Ning Example Both Olympics And Olympic Games Are Mapped To A Freebase Topic Called Olympic Games Based On This Information A Keyphrase Ex Tractor Can Determine That The Two Candidates Are Aliases And Should Output Only One Of Them Thus Preventing A Redundancy Error Next We Discuss How Infrequency Errors Could Be Addressed Using Background Knowledge A Natural Way To Handle This Problem Would Be To Make An Infrequent Keyphrase Frequent To Ac Complish This We Suggest Exploiting An Inuen Tial Idea In The ...\n",
            "\n",
            "Chunk 79:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 86, 'num_chars': 512}\n",
            "Text: s We Suggest Exploiting An Inuen Tial Idea In The Keyphrase Extraction Literature The Importance Of A Candidate Is Dened In Terms Of How Related It Is To Other Candidates In The Text See Section 331 In Other Words If We Could Relate An Infrequent Keyphrase To Other Candidates In The Text We Could Boost Its Importance We Believe That This Could Be Accomplished Us Ing Background Knowledge The Idea Is To Boost The Importance Of Infrequent Keyphrases Using Their Frequent Counterparts Consider Again Our Running ...\n",
            "\n",
            "Chunk 80:\n",
            "Document ID: af57d828-b15c-4073-b155-bbb65e7005b6\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 23, 'num_chars': 512}\n",
            "Text:  Frequent Counterparts Consider Again Our Running Example All Four Systems Have Managed To Identify Ben Johnson As A Keyphrase Due To Its 1269                                                                                                                                                                                                                                                                                                                                                                                  ...\n",
            "\n",
            "Chunk 81:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 95, 'num_chars': 512}\n",
            "Text: Signicant Presence Hence We Can Boost The Im Portance Of 100Meter Dash And Gold Medal If We Can Relate Them To Ben Johnson To Do So Note That Freebase Maps A Candi Date To One Or More Predened Topics Each Of Which Is Associated With One Or More Types Types Are Similar To Entity Classes For Instance The Candidate Ben Johnson Is Mapped To A Freebase Topic With The Same Name Which Is Associated With Freebase Types Such As Person Athlete And Olympic Athlete Types Are Dened For A Specic Domain In Freebase For In...\n",
            "\n",
            "Chunk 82:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 92, 'num_chars': 512}\n",
            "Text: s Are Dened For A Specic Domain In Freebase For Instance Person Ath Lete And Olympic Athlete Are Dened In The People Sports And Olympics Domains Respectively Next Consider The Two Infrequent Candidates 100Meter Dash And Gold Medal 100Meter Dash Is Mapped To The Topic Sprint Of Type Sports In The Sports Do Main Whereas Gold Medal Is Mapped To A Topic With The Same Name Of Type Olympic Medal In The Olympics Domain Consequently We Can Relate 100Meter Dash To Ben Johnson Via The Sports Do Main Ie They Belong To...\n",
            "\n",
            "Chunk 83:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 82, 'num_chars': 512}\n",
            "Text: n Johnson Via The Sports Do Main Ie They Belong To Different Types Under The Same Domain Additionally Gold Medal Can Be Related To Ben Johnson Via The Olympics Domain As Discussed Before The Relationship Between Two Candidates Is Traditionally Established Using Cooccurrence Information However Using Co Occurrence Windows Has Its Shortcomings First An Adhoc Window Size Cannot Capture Related Can Didates That Are Not Inside The Window So It Is Difcult To Predict 100Meter Dash And Gold Medal As Keyphrases They...\n",
            "\n",
            "Chunk 84:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 85, 'num_chars': 512}\n",
            "Text: ct 100Meter Dash And Gold Medal As Keyphrases They Are More Than 10 Tokens Away From Frequent Words Such As Johnson And Olympics Second The Candidates Inside A Window Are All Assumed To Be Related To Each Other But It Is Apparently An Overly Simplistic Assumption There Have Been A Few Attempts To Design Wikipedia Based Relatedness Measures With Promising Ini Tial Results Grineva Et Al 2009 Liu Et Al 2009B Medelyan Et Al 20094 Overgeneration Errorscould Similarly Be Ad Dressed Using Background Knowledge Reca...\n",
            "\n",
            "Chunk 85:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 88, 'num_chars': 512}\n",
            "Text: arly Be Ad Dressed Using Background Knowledge Recall That Olympic Movement Is Not A Keyphrase In Our Ex Ample Although It Includes An Important Word Ie Olympic Freebase Maps Olympic Movement To A Topic With The Same Name Which Is Associated With A Type Called Musical Recording In The Mu Sic Domain However It Does Not Map Olympic 4Note That It May Be Difcult To Employ Our Recommen Dations To Address Infrequency Errors In Informal Text With Uncorrelated Topics Because The Keyphrases It Contains May Not Be Rel...\n",
            "\n",
            "Chunk 86:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 84, 'num_chars': 512}\n",
            "Text:  Because The Keyphrases It Contains May Not Be Related To Each Other See Section 2 Movement To Any Topic In The Olympics Domain The Absence Of Such A Mapping In The Olympics Domain Could Be Used By A Keyphrase Extractor As A Supporting Evidence Against Predicting Olympic Movement As A Keyphrase Finally As Mentioned Beforeevaluation Errors Should Not Be Considered Errors Made By A Sys Tem Nevertheless They Reveal A Problem With The Way Keyphrase Extractors Are Currently Evaluated To Address This Problem One ...\n",
            "\n",
            "Chunk 87:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: e Currently Evaluated To Address This Problem One Possibility Is To Con Duct Human Evaluations Cheaper Alternatives In Clude Having Human Annotators Identify Semanti Cally Equivalent Keyphrases During Manual Label Ing And Designing Scoring Programs That Can Au Tomatically Identify Such Semantic Equivalences 6 Conclusion And Future Directions We Have Presented A Survey Of The State Of The Art In Automatic Keyphrase Extraction While Unsu Pervised Approaches Have Started To Rival Their Su Pervised Counterparts...\n",
            "\n",
            "Chunk 88:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 80, 'num_chars': 512}\n",
            "Text: ve Started To Rival Their Su Pervised Counterparts In Performance The Task Is Far From Being Solved As Reected By The Fairly Poor Stateoftheart Results On Various Commonly Used Evaluation Datasets Our Analysis Revealed That There Are At Least Three Major Challenges Ahead 1 Incorporating Background Knowledge While Much Recent Work Has Focused On Algo Rithmic Development Keyphrase Extractors Need To Have A Deeper Understanding Of A Document In Order To Reach The Next Level Of Performance Such An Understanding...\n",
            "\n",
            "Chunk 89:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 77, 'num_chars': 512}\n",
            "Text: he Next Level Of Performance Such An Understanding Can Be Facilitated By The Incorporation Of Background Knowledge 2 Handling Long Documents While It May Be Possible To Design Better Algorithms To Handle The Large Number Of Candidates In Long Documents We Believe That Employing Sophisticated Features Es Pecially Those That Encode Background Knowledge Will Enable Keyphrases And Nonkeyphrases To Be Distinguished More Easily Even In The Presence Of A Large Number Of Candidates 3 Improving Evaluation Schemesto ...\n",
            "\n",
            "Chunk 90:\n",
            "Document ID: e0fc76c8-1399-4e07-b601-9146bbf6c8eb\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 71, 'num_chars': 512}\n",
            "Text: er Of Candidates 3 Improving Evaluation Schemesto More Ac Curately Measure The Performance Of Keyphrase Extractors They Should Not Be Penalized For Evalu Ation Errors We Have Suggested Several Possibili Ties As To How This Problem Can Be Addressed Acknowledgments We Thank The Anonymous Reviewers For Their De Tailed And Insightful Comments On Earlier Drafts Of This Paper This Work Was Supported In Part By Nsf Grants Iis1147644 And Iis1219142 1270                                                               ...\n",
            "\n",
            "Chunk 91:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 77, 'num_chars': 512}\n",
            "Text: References Ken Barker And Nadia Cornacchia 2000 Using Noun Phrase Heads To Extract Document Keyphrases In Proceedings Of The 13Th Biennial Conference Of The Canadian Society On Computational Studies Of In Telligence Pages 4052 Gabor Berend 2011 Opinion Expression Mining By Exploiting Keyphrase Extraction In Proceedings Of The 5Th International Joint Conference On Natural Language Processing Pages 11621170 David M Blei Andrew Y Ng And Michael I Jordan 2003 Latent Dirichlet Allocation Journal Of Ma Chine Lear...\n",
            "\n",
            "Chunk 92:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 74, 'num_chars': 512}\n",
            "Text: tent Dirichlet Allocation Journal Of Ma Chine Learning Research 39931022 Kurt Bollacker Colin Evans Praveen Paritosh Tim Sturge And Jamie Taylor 2008 Freebase A Col Laboratively Created Graph Database For Structuring Human Knowledge In Proceedings Of The 2008 Acm Sigmod International Conference On Management Of Data Pages 12471250 Adrien Bougouin Florian Boudin And Beatrice Daille 2013 Topicrank Graphbased Topic Ranking For Keyphrase Extraction In Proceedings Of The 6Th In Ternational Joint Conference On Na...\n",
            "\n",
            "Chunk 93:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 80, 'num_chars': 512}\n",
            "Text: s Of The 6Th In Ternational Joint Conference On Natural Language Processing Pages 543551 Sergey Brin And Lawrence Page 1998 The Anatomy Of A Largescale Hypertextual Web Search Engine Computer Networks 3017107117 Mo Chen Jiantao Sun Huajun Zeng And Kwokyan Lam 2005 A Practical System Of Keyphrase Ex Traction For Web Pages In Proceedings Of The 14Th Acm International Conference On Information And Knowledge Management Pages 277278 Zhuoye Ding Qi Zhang And Xuanjing Huang 2011 Keyphrase Extraction From Online Ne...\n",
            "\n",
            "Chunk 94:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text: ing Huang 2011 Keyphrase Extraction From Online News Using Binary Integer Programming In Proceedings Of The 5Th In Ternational Joint Conference On Natural Language Processing Pages 165173 Mark Dredze Hanna M Wallach Danny Puller And Fernando Pereira 2008 Generating Summary Key Words For Emails Using Topics In Proceedings Of The 13Th International Conference On Intelligent User Interfaces Pages 199206 Samhaa R Elbeltagy And Ahmed A Rafea 2009 Kpminer A Keyphrase Extraction System For En Glish And Arabic Docu...\n",
            "\n",
            "Chunk 95:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text: ase Extraction System For En Glish And Arabic Documents Information Systems 341132144 Samhaa R Elbeltagy And Ahmed Rafea 2010 Kp Miner Participation In Semeval2 In Proceedings Of The 5Th International Workshop On Semantic Eval Uation Pages 190193 Eibe Frank Gordon W Paynter Ian H Witten Carl Gutwin And Craig G Nevillmanning 1999 Domainspecic Keyphrase Extraction In Proceed Ings Of 16Th International Joint Conference On Arti Cial Intelligence Pages 668673 Maria Grineva Maxim Grinev And Dmitry Lizorkin 2009 E...\n",
            "\n",
            "Chunk 96:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 83, 'num_chars': 512}\n",
            "Text: ia Grineva Maxim Grinev And Dmitry Lizorkin 2009 Extracting Key Terms From Noisy And Multi Theme Documents In Proceedings Of The 18Th In Ternational Conference On World Wide Web Pages 661670 Carl Gutwin Gordon Paynter Ian Witten Craig Nevill Manning And Eibe Frank 1999 Improving Brows Ing In Digital Libraries With Keyphrase Indexes De Cision Support Systems 2781104 Khaled M Hammouda Diego N Matute And Mo Hamed S Kamel 2005 Corephrase Keyphrase Ex Traction For Document Clustering In Proceedings Of The 4Th In...\n",
            "\n",
            "Chunk 97:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text: r Document Clustering In Proceedings Of The 4Th International Conference On Machine Learn Ing And Data Mining In Pattern Recognition Pages 265274 Kazi Saidul Hasan And Vincent Ng 2010 Conun Drums In Unsupervised Keyphrase Extraction Mak Ing Sense Of The Stateoftheart In Proceedings Of The 23Rd International Conference On Computa Tional Linguistics Posters Pages 365373 Chong Huang Yonghong Tian Zhi Zhou Charles X Ling And Tiejun Huang 2006 Keyphrase Extrac Tion Using Semantic Networks Structure Analysis In P...\n",
            "\n",
            "Chunk 98:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 77, 'num_chars': 512}\n",
            "Text: on Using Semantic Networks Structure Analysis In Proceedings Of The 6Th International Conference On Data Mining Pages 275284 Anette Hulth And Be Ata B Megyesi 2006 A Study On Automatically Extracted Keywords In Text Catego Rization In Proceedings Of The 21St International Conference On Computational Linguistics And The 44Th Annual Meeting Of The Association For Compu Tational Linguistics Pages 537544 Anette Hulth Jussi Karlgren Anna Jonsson Henrik Bostrom And Lars Asker 2001 Automatic Key Word Extraction Us...\n",
            "\n",
            "Chunk 99:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: d Lars Asker 2001 Automatic Key Word Extraction Using Domain Knowledge In Pro Ceedings Of The 2Nd International Conference On Computational Linguistics And Intelligent Text Pro Cessing Pages 472482 Anette Hulth 2003 Improved Automatic Keyword Ex Traction Given More Linguistic Knowledge In Pro Ceedings Of The 2003 Conference On Empirical Meth Ods In Natural Language Processing Pages 216 223 Anette Hulth 2004 Enhancing Linguistically Ori Ented Automatic Keyword Extraction In Proceedings Of The Human Language ...\n",
            "\n",
            "Chunk 100:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text: d Extraction In Proceedings Of The Human Language Technology Conference Of The North American Chapter Of The Association For Computational Linguistics Short Papers Pages 17 20 Xin Jiang Yunhua Hu And Hang Li 2009 A Rank Ing Approach To Keyphrase Extraction In Proceed Ings Of The 32Nd International Acm Sigir Confer Ence On Research And Development In Information Retrieval Pages 756757 Daniel Kelleher And Saturnino Luz 2005 Automatic Hypertext Keyphrase Detection In Proceedings Of The 19Th International Joint...\n",
            "\n",
            "Chunk 101:\n",
            "Document ID: 9c39e96d-f031-49a6-ac59-6aef90557f47\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 14, 'num_chars': 512}\n",
            "Text: ion In Proceedings Of The 19Th International Joint Conference On Articial In Telligence Pages                                                                                                                                                                                                                                                                                                                                                                                                                                   ...\n",
            "\n",
            "Chunk 102:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 79, 'num_chars': 512}\n",
            "Text: Su Nam Kim And Timothy Baldwin 2012 Extracting Keywords From Multiparty Live Chats In Proceed Ings Of The 26Th Pacic Asia Conference On Lan Guage Information And Computation Pages 199 208 Su Nam Kim And Minyen Kan 2009 Reexamining Automatic Keyphrase Extraction Approaches In Scien Tic Articles In Proceedings Of The Aclijcnlp Workshop On Multiword Expressions Pages 916 Su Nam Kim Timothy Baldwin And Minyen Kan 2010A Evaluating Ngram Based Evaluation Metrics For Automatic Keyphrase Extraction In Proceedings O...\n",
            "\n",
            "Chunk 103:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: or Automatic Keyphrase Extraction In Proceedings Of The 23Rd International Conference On Computa Tional Linguistics Pages 572580 Su Nam Kim Olena Medelyan Minyen Kan And Timothy Baldwin 2010B Semeval2010 Task 5 Automatic Keyphrase Extraction From Scientic Arti Cles In Proceedings Of The 5Th International Work Shop On Semantic Evaluation Pages 2126 Su Nam Kim Olena Medelyan Minyen Kan And Timothy Baldwin 2013 Automatic Keyphrase Extraction From Scientic Articles Language Re Sources And Evaluation 473723742 N...\n",
            "\n",
            "Chunk 104:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 77, 'num_chars': 512}\n",
            "Text: les Language Re Sources And Evaluation 473723742 Niraj Kumar And Kannan Srinathan 2008 Automatic Keyphrase Extraction From Scientic Documents Us Ing Ngram Ltration Technique In Proceedings Of The 8Th Acm Symposium On Document Engineering Pages 199208 Feifan Liu Deana Pennell Fei Liu And Yang Liu 2009A Unsupervised Approaches For Automatic Key Word Extraction Using Meeting Transcripts In Pro Ceedings Of Human Language Technologies The Annual Conference Of The North American Chap Ter Of The Association For Co...\n",
            "\n",
            "Chunk 105:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text:  North American Chap Ter Of The Association For Computational Linguistics Pages 620628 Zhiyuan Liu Peng Li Yabin Zheng And Maosong Sun 2009B Clustering To Nd Exemplar Terms For Keyphrase Extraction In Proceedings Of The 2009 Conference On Empirical Methods In Natural Lan Guage Processing Pages 257266 Zhiyuan Liu Wenyi Huang Yabin Zheng And Maosong Sun 2010 Automatic Keyphrase Extrac Tion Via Topic Decomposition In Proceedings Of The 2010 Conference On Empirical Methods In Natural Language Processing Pages 3...\n",
            "\n",
            "Chunk 106:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: cal Methods In Natural Language Processing Pages 366376 Zhiyuan Liu Xinxiong Chen Yabin Zheng And Maosong Sun 2011 Automatic Keyphrase Extrac Tion By Bridging Vocabulary Gap In Proceedings Of The 15Th Conference On Computational Natural Lan Guage Learning Pages 135144 Zhiyuan Liu Chen Liang And Maosong Sun 2012 Topical Word Trigger Model For Keyphrase Extraction In Proceedings Of The 24Th International Conference On Computational Linguistics Pages 17151730 Patrice Lopez And Laurent Romary 2010 Humb Automati...\n",
            "\n",
            "Chunk 107:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: atrice Lopez And Laurent Romary 2010 Humb Automatic Key Term Extraction From Scientic Arti Cles In Grobid In Proceedings Of The 5Th Inter National Workshop On Semantic Evaluation Pages 248251 Yutaka Matsuo And Mitsuru Ishizuka 2004 Key Word Extraction From A Single Document Using Word Cooccurrence Statistical Information International Journal On Articial Intelligence Tools 13 Olena Medelyan Eibe Frank And Ian H Witten 2009 Humancompetitive Tagging Using Automatic Keyphrase Extraction In Proceedings Of The 2...\n",
            "\n",
            "Chunk 108:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 72, 'num_chars': 512}\n",
            "Text: matic Keyphrase Extraction In Proceedings Of The 2009 Conference On Empirical Methods In Natural Lan Guage Processing Pages 13181327 Rada Mihalcea And Paul Tarau 2004 Textrank Bringing Order Into Texts In Proceedings Of The 2004 Conference On Empirical Methods In Natural Language Processing Pages 404411 Roberto Navigli And Simone Paolo Ponzetto 2012 Babelnet The Automatic Construction Evaluation And Application Of A Widecoverage Multilingual Se Mantic Network Articial Intelligence  David Newman Nagendra Koi...\n",
            "\n",
            "Chunk 109:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 76, 'num_chars': 512}\n",
            "Text: k Articial Intelligence  David Newman Nagendra Koilada Jey Han Lau And Timothy Baldwin 2012 Bayesian Text Segmenta Tion For Index Term Identication And Keyphrase Ex Traction In Proceedings Of The 24Th International Conference On Computational Linguistics Pages 20772092 Thuy Dung Nguyen And Minyen Kan 2007 Keyphrase Extraction In Scientic Publications In Proceedings Of The International Conference On Asian Digital Libraries Pages 317326 Chau Q Nguyen And Tuoi T Phan 2009 An Ontologybased Approach For Key Phr...\n",
            "\n",
            "Chunk 110:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 78, 'num_chars': 512}\n",
            "Text:  T Phan 2009 An Ontologybased Approach For Key Phrase Extraction In Proceedings Of The Joint Conference Of The 47Th Annual Meeting Of The Association For Computa Tional Linguistics And The 4Th International Joint Conference On Natural Language Processing Short Papers Pages 181184 Paul Over 2001 Introduction To Duc2001 An In Trinsic Evaluation Of Generic News Text Summariza Tion Systems In Proceedings Of The 2001 Document Understanding Conference Marisanna Paukkeri Ilari T Nieminen Matti P Olla And Timo Honk...\n",
            "\n",
            "Chunk 111:\n",
            "Document ID: 4f8771ae-f7c9-4898-b0b3-093a86477f50\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 52, 'num_chars': 512}\n",
            "Text: ukkeri Ilari T Nieminen Matti P Olla And Timo Honkela 2008 A Languageindependent Approach To Keyphrase Extraction And Evaluation In Proceedings Of The 22Nd International Conference On Computational Linguistics Companion Volume Posters Pages 8386 Gerard Salton And Christopher Buckley 1988 Term Weighting Approaches In Automatic Text Retrievalin Formation Processing And Management  1272                                                                                                                              ...\n",
            "\n",
            "Chunk 112:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 82, 'num_chars': 512}\n",
            "Text: Min Song Ilyeol Song And Xiaohua Hu 2003 Kpspotter A Exible Information Gainbased Keyphrase Extraction System In Proceedings Of The 5Th Acm International Workshop On Web Informa Tion And Data Management Pages 5053 Fabian M Suchanek Gjergji Kasneci And Gerhard Weikum 2007 Y Ago A Core Of Semantic Knowl Edge In Proceedings Of The 16Th International World Wide Web Conference Pages 697706 Takashi Tomokiyo And Matthew Hurst 2003 A Lan Guage Model Approach To Keyphrase Extraction In Proceedings Of The Acl Worksho...\n",
            "\n",
            "Chunk 113:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 72, 'num_chars': 512}\n",
            "Text: hrase Extraction In Proceedings Of The Acl Workshop On Multiword Ex Pressions Pages 3340 Peter Turney 1999 Learning To Extract Keyphrases From Text National Research Council Canada In Stitute For Information Technology Technical Report Erb1057 Peter Turney 2000 Learning Algorithms For Keyphrase Extraction Information Retrieval 2303336 Peter Turney 2003 Coherent Keyphrase Extraction Via Web Mining In Proceedings Of The 18Th Inter National Joint Conference On Articial Intelligence Pages 434439 Xiaojun Wan And...\n",
            "\n",
            "Chunk 114:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 72, 'num_chars': 512}\n",
            "Text: Articial Intelligence Pages 434439 Xiaojun Wan And Jianguo Xiao 2008A Col Labrank Towards A Collaborative Approach To Singledocument Keyphrase Extraction In Proceed Ings Of The 22Nd International Conference On Com Putational Linguistics Pages 969976 Xiaojun Wan And Jianguo Xiao 2008B Single Document Keyphrase Extraction Using Neighborhood Knowledge In Proceedings Of The 23Rd Aaai Con Ference On Articial Intelligence Pages 855860 Xiaojun Wan Jianwu Yang And Jianguo Xiao 2007 Towards An Iterative Reinforcemen...\n",
            "\n",
            "Chunk 115:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 76, 'num_chars': 512}\n",
            "Text: ianguo Xiao 2007 Towards An Iterative Reinforcement Approach For Si Multaneous Document Summarization And Keyword Extraction In Proceedings Of The 45Th Annual Meet Ing Of The Association Of Computational Linguistics Pages 552559 Chen Wang And Sujian Li 2011 Corankbayes Bayesian Learning To Rank Under The Cotraining Framework And Its Application In Keyphrase Extrac Tion In Proceedings Of The 20Th Acm International Conference On Information And Knowledge Man Agement Pages 22412244 Ian H Witten Gordon W Paynte...\n",
            "\n",
            "Chunk 116:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 80, 'num_chars': 512}\n",
            "Text: gement Pages 22412244 Ian H Witten Gordon W Paynter Eibe Frank Carl Gutwin And Craig G Nevillmanning 1999 Kea Practical Automatic Keyphrase Extraction In Pro Ceedings Of The 4Th Acm Conference On Digital Li Braries Pages 254255 Yifang Brook Wu Quanzhi Li Razvan Stefan Bot And Xin Chen 2005 Domainspecic Keyphrase Extraction In Proceedings Of The 14Th Acm Inter National Conference On Information And Knowledge Management Pages 283284 Wentau Yih Joshua Goodman And Vitor R Carvalho 2006 Finding Advertising Keywo...\n",
            "\n",
            "Chunk 117:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 75, 'num_chars': 512}\n",
            "Text: nd Vitor R Carvalho 2006 Finding Advertising Keywords On Web Pages In Proceedings Of The 15Th International Conference On World Wide Web Pages 213222 Wei You Dominique Fontaine And Jeanpaul Barthes 2009 Automatic Keyphrase Extraction With A Rened Candidate Set In Proceedings Of The Ieeewicacm International Joint Conference On Web Intelligence And Intelligent Agent Technology Pages 576579 Torsten Zesch And Iryna Gurevych 2009 Approxi Mate Matching For Evaluating Keyphrase Extraction In Proceedings Of The Int...\n",
            "\n",
            "Chunk 118:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 71, 'num_chars': 512}\n",
            "Text: ing Keyphrase Extraction In Proceedings Of The International Conference On Recent Advances In Natural Language Processing 2009 Pages 484489 Hongyuan Zha 2002 Generic Summarization And Keyphrase Extraction Using Mutual Reinforcement Principle And Sentence Clustering In Proceedings Of 25Th Annual International Acm Sigir Confer Ence On Research And Development In Information Retrieval Pages 113120 Yongzheng Zhang Nur Zincirheywood And Evange Los Milios 2004 World Wide Web Site Summariza Tion Web Intelligence A...\n",
            "\n",
            "Chunk 119:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 82, 'num_chars': 512}\n",
            "Text: ld Wide Web Site Summariza Tion Web Intelligence And Agent Systems 23953 Yongzheng Zhang Nur Zincirheywood And Evange Los Milios 2005 Narrative Text Classication For Automatic Key Phrase Extraction In Web Document Corpora In Proceedings Of The 7Th Acm Interna Tional Workshop On Web Information And Data Man Agement Pages 5158 Xin Zhao Jing Jiang Jing He Yang Song Palakorn Achanauparp Eepeng Lim And Xiaoming Li 2011 Topical Keyphrase Extraction From Twitter In Proceedings Of The 49Th Annual Meeting Of The Ass...\n",
            "\n",
            "Chunk 120:\n",
            "Document ID: 23fc5787-f204-4923-b0e1-591f771f2c63\n",
            "Metadata: {'file_name': 'Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'file_path': '/content/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf', 'num_tokens': 16, 'num_chars': 512}\n",
            "Text:  Proceedings Of The 49Th Annual Meeting Of The Association For Computational Linguistics Human Language Technologies Pages                                                                                                                                                                                                                                                                                                                                                                                                      ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#storing all the data in chroma db"
      ],
      "metadata": {
        "id": "IfoOCpFHC8qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS6OOO5NC6cf",
        "outputId": "b62409ad-dc73-498e-8e77-44dd27200298"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.21.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.21.0-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=9945616f63342b8bc0b6619365039e7499c2392fdac71f4b700c603bf5a10dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.31.0\n",
            "    Uninstalling opentelemetry-api-1.31.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.31.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.52b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.52b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.31.0\n",
            "    Uninstalling opentelemetry-sdk-1.31.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.31.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.11 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-api-1.31.1 opentelemetry-exporter-otlp-proto-common-1.31.1 opentelemetry-exporter-otlp-proto-grpc-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-proto-1.31.1 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 opentelemetry-util-http-0.52b1 overrides-7.7.0 posthog-3.21.0 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.46.1 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall llama-index-vector-stores-chroma -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79U2Qy5s68fJ",
        "outputId": "1f2ce5ed-52da-4cbf-c225-f20aa0c9c6f7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping llama-index-vector-stores-chroma as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install --upgrade llama-index\n",
        "!pip uninstall llama-index-vector-stores-chroma -y # uninstall the conflicting package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiTsNvNbDF_8",
        "outputId": "46c3aefd-e236-4145-eb1c-f5adb3dcde5c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.26)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.16)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.7)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "\u001b[33mWARNING: Skipping llama-index-vector-stores-chroma as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-vector-stores-chroma # Install the necessary package to add vector_stores to llama_index\n",
        "# Install the necessary packages\n",
        "!pip install --upgrade llama-index\n",
        "!pip uninstall llama-index-vector-stores-chroma -y # uninstall the conflicting package\n",
        "\n",
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utuJQyN_DJP4",
        "outputId": "1f115d8e-b939-49e6-8267-e159f117f66b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-chroma\n",
            "  Downloading llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl.metadata (696 bytes)\n",
            "Requirement already satisfied: chromadb>=0.5.17 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.6.3)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.12.25)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.4)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2025.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.18.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.11.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.29.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (14.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
            "Downloading llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: llama-index-vector-stores-chroma\n",
            "Successfully installed llama-index-vector-stores-chroma-0.4.1\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.26)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.16)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.7)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Found existing installation: llama-index-vector-stores-chroma 0.4.1\n",
            "Uninstalling llama-index-vector-stores-chroma-0.4.1:\n",
            "  Successfully uninstalled llama-index-vector-stores-chroma-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-vector-stores-chroma\n",
        "from typing import Collection\n",
        "from pathlib import Path\n",
        "from chromadb import PersistentClient\n",
        "from chromadb.api.types import Documents, Embeddings, Metadatas, IDs\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore  # Correct import\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4CDFkH9DPxf",
        "outputId": "d8bc7663-beac-486f-ba45-8e4fdde4465f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-chroma\n",
            "  Using cached llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl.metadata (696 bytes)\n",
            "Requirement already satisfied: chromadb>=0.5.17 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.6.3)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.12.25)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.4)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2025.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.18.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.11.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.29.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (14.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
            "Using cached llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: llama-index-vector-stores-chroma\n",
            "Successfully installed llama-index-vector-stores-chroma-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chroma_db = \"./chroma_db\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "Path(chroma_db).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    # Initialize ChromaDB\n",
        "    chroma_client = PersistentClient(path=str(chroma_db))\n",
        "    vector_store = ChromaVectorStore(chroma_client, collection_name=\"chunks\")\n",
        "\n",
        "    print(\"Chroma DB installed and initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Chroma DB encountered an error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l5Wlwn1DTy7",
        "outputId": "6b83ecb9-2f87-46a5-9245-29fb72378542"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chroma DB installed and initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install --upgrade llama-index\n",
        "!pip uninstall llama-index-vector-stores-chroma -y # uninstall the conflicting package\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOC1PkDfDW34",
        "outputId": "36250c84-0027-4f56-b960-e864e574bc5c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.26)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.16)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.7)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Found existing installation: llama-index-vector-stores-chroma 0.4.1\n",
            "Uninstalling llama-index-vector-stores-chroma-0.4.1:\n",
            "  Successfully uninstalled llama-index-vector-stores-chroma-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.ingestion import IngestionPipeline  # Correct import for IngestionPipeline\n",
        "from llama_index.core.node_parser.text import SentenceSplitter  # Correct import for SentenceSplitter\n",
        "from llama_index.core.node_parser.text import TokenTextSplitter  # Correct import for TokenTextSplitter\n",
        "\n",
        "# Ensure you have the vector_store object properly initialized\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        TokenTextSplitter(chunk_size=1024),  # TokenTextSplitter now requires a chunk_size parameter\n",
        "        SentenceSplitter(chunk_size=1024, chunk_overlap=0),  # Corrected parameter name\n",
        "    ],\n",
        "    vector_store=vector_store,\n",
        ")\n",
        "\n",
        "print(\"Ingestion pipeline initialized successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO_UwgjZDZN1",
        "outputId": "9f3a4e41-038f-465a-fdd5-8583af0314f3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingestion pipeline initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "  nodes = pipeline.run(documents=document)\n",
        "  if not nodes:\n",
        "    print(\"no nodes were created\")\n",
        "    exit()\n",
        "  print(f\"{len(nodes)} document nodes created in chroma db\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RGhVCXbDdkH",
        "outputId": "5fbac34f-527b-4986-b5e7-bb70e463751b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 document nodes created in chroma db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  nodes = pipeline.run(documents=document)\n",
        "  if not nodes:\n",
        "    print(\"no nodes were created\")\n",
        "    exit()\n",
        "  print(f\"{len(nodes)} document nodes created in chroma db\")\n",
        "\n",
        "  # Print all nodes:\n",
        "  for i, node in enumerate(nodes):\n",
        "    print(f\"Node {i + 1}:\")\n",
        "    print(f\"  Text: {node.text}\")  # Print the text content of the node\n",
        "    print(f\"  ID: {node.id_}\")    # Print the unique ID of the node\n",
        "    print(\"-\" * 20)  # Add a separator for better readability\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clC_AyJ6Dfl8",
        "outputId": "9a49b980-d67d-4826-b358-383edf01ac1e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 document nodes created in chroma db\n",
            "Node 1:\n",
            "  Text: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics pages 12621273 Baltimore Maryland USA June 2325 2014c2014 Association for Computational Linguistics Automatic Keyphrase Extraction A Survey of the State of the Art Kazi Saidul Hasanand Vincent Ng Human Language Technology Research Institute University of Texas at Dallas Richardson TX 750830688 saidulvincehltutdallasedu Abstract While automatic keyphrase extraction has been examined extensively stateofthe art performance on this task is still much lower than that on many core natural lan guage processing tasks We present a sur vey of the state of the art in automatic keyphrase extraction examining the major sources of errors made by existing systems and discussing the challenges ahead 1 Introduction Automatic keyphrase extraction concerns the au tomatic selection of important and topical phrases from the body of a document Turney 2000 In other words its goal is to extract a set of phrases that are related to the main topics discussed in a given document Tomokiyo and Hurst 2003 Liu et al 2009b Ding et al 2011 Zhao et al 2011 Document keyphrases have enabled fast and ac curate searching for a given document from a large text collection and have exhibited their potential in improving many natural language processing NLP and information retrieval IR tasks such as text summarization Zhang et al 2004 text categorization Hulth and Megyesi 2006 opin ion mining Berend 2011 and document index ing Gutwin et al 1999 Owing to its importance automatic keyphrase extraction has received a lot of attention However the task is far from being solved stateoftheart performance on keyphrase extraction is still much lower than that on many core NLP tasks Liu et al 2010 Our goal in this paper is to survey the state of the art in keyphrase extraction examining the major sources of errors made by existing systems and discussing the challenges ahead 2 Corpora Automatic keyphrase extraction systems have been evaluated on corpora from a variety of sources ranging from long scientic publications to short paper abstracts and email messages Ta ble 1 presents a listing of the corpora grouped by their sources as well as their statistics 1 There are at least four corpusrelated factors that affect the difculty of keyphrase extraction Length The difculty of the task increases with the length of the input document as longer doc uments yield more candidate keyphrases ie phrases that are eligible to be keyphrases see Sec tion 31 For instance each Inspec abstract has on average 10 annotatorassigned keyphrases and 34 candidate keyphrases In contrast a scientic paper typically has at least 10 keyphrases and hun dreds of candidate keyphrases yielding a much bigger search space Hasan and Ng 2010 Conse quently it is harder to extract keyphrases from sci entic papers technical reports and meeting tran scripts than abstracts emails and news articles Structural consistency In a structured doc ument there are certain locations where a keyphrase is most likely to appear For instance most of a scientic papers keyphrases should ap pear in the abstract and the introduction While structural information has been exploited to ex tract keyphrases from scientic papers eg title section information Kim et al 2013 web pages eg metadata Yih et al 2006 and chats eg dialogue acts Kim and Baldwin 2012 it is most useful when the documents from a source exhibit structural similarity For this reason structural in formation is likely to facilitate keyphrase extrac tion from scientic papers and technical reports because of their standard format ie standard sections such as abstract introduction conclusion etc In contrast the lack of structural consistency in other types of structured documents eg web pages which can be blogs forums or reviews 1Many of the publicly available corpora can be found in httpgithubcomsnkimAutomaticKeyphraseExtraction and httpcodegooglecompmauiindexerdownloadslist 1262\n",
            "  ID: 8d92d8f2-69f5-45b5-8d66-bcb547a415c8\n",
            "--------------------\n",
            "Node 2:\n",
            "  Text: Source DatasetContributor Statistics Documents Tokensdoc Keysdoc Paper abstracts Inspec Hulth 2003 2000 200 10 Scientic papers NUS corpus Nguyen and Kan 2007 211 8K 11 citeulikeorg Medelyan et al 2009 180 5 SemEval2010 Kim et al 2010b 284 5K 15 Technical reports NZDL Witten et al 1999 1800 News articles DUC2001 Wan and Xiao 2008b 308 900 8 Reuters corpus Hulth and Megyesi 2006  Web pages Yih et al 2006 828 Hammouda et al 2005 312 500 Blogs Grineva et al 2009 252 1K 8 Meeting transcripts ICSI Liu et al 2009a 161 16K 4 Emails Enron corpus Dredze et al 2008 14659 Live chats Library of Congress Kim and Baldwin 2012 15 10 Table 1 Evaluation datasets Publicly available datasets are marked with an asterisk may render structural information less useful Topic change An observation commonly ex ploited in keyphrase extraction from scientic ar ticles and news articles is that keyphrases typically appear not only at the beginning Witten et al 1999 but also at the end Medelyan et al 2009 of a document This observation does not neces sarily hold for conversational text eg meetings chats however The reason is simple in a conver sation the topics ie its talking points change as the interaction moves forward in time and so do the keyphrases associated with a topic One way to address this complication is to detect a topic change in conversational text Kim and Baldwin 2012 However topic change detection is not al ways easy while the topics listed in the form of an agenda at the beginning of formal meeting tran scripts can be exploited such clues are absent in casual conversations eg chats Topic correlation Another observation com monly exploited in keyphrase extraction from scientic articles and news articles is that the keyphrases in a document are typically related to each other Turney 2003 Mihalcea and Tarau 2004 However this observation does not nec essarily hold for informal text eg emails chats informal meetings personal blogs where people can talk about any number of potentially uncorre lated topics The presence of uncorrelated topics implies that it may no longer be possible to exploit relatedness and therefore increases the difculty of keyphrase extraction 3 Keyphrase Extraction Approaches A keyphrase extraction system typically operates in two steps 1 extracting a list of wordsphrases that serve as candidate keyphrases using some heuristics Section 31 and 2 determining which of these candidate keyphrases are correct keyphrases using supervised Section 32 or un supervised Section 33 approaches 31 Selecting Candidate Words and Phrases As noted before a set of phrases and words is typically extracted as candidate keyphrases using heuristic rules These rules are designed to avoid spurious instances and keep the number of candi dates to a minimum Typical heuristics include 1 using a stop word list to remove stop words Liu et al 2009b 2 allowing words with certain part ofspeech tags eg nouns adjectives verbs to be candidate keywords Mihalcea and Tarau 2004 Wan and Xiao 2008b Liu et al 2009a 3 al lowing ngrams that appear in Wikipedia article titles to be candidates Grineva et al 2009 and 4 extracting ngrams Witten et al 1999 Hulth 2003 Medelyan et al 2009 or noun phrases Barker and Cornacchia 2000 Wu et al 2005 that satisfy predened lexicosyntactic patterns Nguyen and Phan 2009 Many of these heuristics have proven effective with their high recall in extracting gold keyphrases from various sources However for a long docu ment the resulting list of candidates can be long Consequently different pruning heuristics have been designed to prune candidates that are un likely to be keyphrases Huang et al 2006 Kumar and Srinathan 2008 ElBeltagy and Rafea 2009 You et al 2009 Newman et al 2012 32 Supervised Approaches Research on supervised approaches to keyphrase extraction has focused on two issues task refor mulation and feature design 1263\n",
            "  ID: b075b3ee-de03-48bb-b45c-ecac1d74abbb\n",
            "--------------------\n",
            "Node 3:\n",
            "  Text: 321 Task Reformulation Early supervised approaches to keyphrase extrac tion recast this task as a binaryclassication prob lem Frank et al 1999 Turney 1999 Witten et al 1999 Turney 2000 The goal is to train a classier on documents annotated with keyphrases to determine whether a candidate phrase is a keyphrase Keyphrases and nonkeyphrases are used to generate positive and negative examples respectively Different learning algorithms have been used to train this classier including na ve Bayes Frank et al 1999 Witten et al 1999 decision trees Turney 1999 Turney 2000 bag ging Hulth 2003 boosting Hulth et al 2001 maximum entropy Yih et al 2006 Kim and Kan 2009 multilayer perceptron Lopez and Romary 2010 and support vector machines Jiang et al 2009 Lopez and Romary 2010 Recasting keyphrase extraction as a classica tion problem has its weaknesses however Recall that the goal of keyphrase extraction is to identify the most representative phrases for a document In other words if a candidate phrase c1 is more representative than another candidate phrasec2 c1 should be preferred to c2 Note that a binary clas sier classies each candidate keyphrase indepen dently of the others and consequently it does not allow us to determine which candidates are better than the others Hulth 2004 Wang and Li 2011 Motivated by this observation Jiang et al 2009 propose a ranking approach to keyphrase extraction where the goal is to learn a ranker to rank two candidate keyphrases This pairwise ranking approach therefore introduces competi tion between candidate keyphrases and has been shown to signicantly outperform KEA Witten et al 1999 Frank et al 1999 a popular su pervised baseline that adopts the traditional super vised classication approach Song et al 2003 Kelleher and Luz 2005 322 Features The features commonly used to represent an in stance for supervised keyphrase extraction can be broadly divided into two categories 3221 WithinCollection Features Withincollection features are computed based solely on the training documents These features can be further divided into three types Statistical featuresare computed based on sta tistical information gathered from the training documents Three such features have been exten sively used in supervised approaches The rst one tfidf Salton and Buckley 1988 is com puted based on candidate frequency in the given text and inverse document frequency ie number of other documents where the candidate appears2 The second one the distance of a phrase is de ned as the number of words preceding its rst occurrence normalized by the number of words in the document Its usefulness stems from the fact that keyphrases tend to appear early in a docu ment The third one supervised keyphraseness encodes the number of times a phrase appears as a keyphrase in the training set This feature is de signed based on the assumption that a phrase fre quently tagged as a keyphrase is more likely to be a keyphrase in an unseen document These three features form the feature set of KEA Witten et al 1999 Frank et al 1999 and have been shown to perform consistently well on documents from var ious sources Yih et al 2006 Kim et al 2013 Other statistical features includephrase length and spread ie the number of words between the rst and last occurrences of a phrase in the document Structural features encode how different in stances of a candidate keyphrase are located in different parts of a document A phrase is more likely to be a keyphrase if it appears in the ab stract or introduction of a paper or in the metadata section of a web page In fact features that en code how frequently a candidate keyphrase occurs in various sections of a scientic paper eg in troduction conclusion Nguyen and Kan 2007 and those that encode the location of a candidate keyphrase in a web page eg whether it appears in the title Chen et al 2005 Yih et al 2006 have been shown to be useful for the task Syntactic features encode the syntactic pat terns of a candidate keyphrase For example a candidate keyphrase has been encoded as 1 a PoS tag sequence which denotes the sequence of partofspeech tags assigned to its words and 2 a sufx sequence which is the sequence of morphological sufxes of its words Yih et al 2006 Nguyen and Kan 2007 Kim and Kan 2009 However ablation studies conducted on web pages Yih et al 2006 and scientic articles 2A tfidfbased baseline where candidate keyphrases are ranked and selected according to tfidf has been widely used by both supervised and unsupervised approaches Zhang et al 2005 Dredze et al 2008 Paukkeri et al 2008\n",
            "  ID: 45b02d7d-affe-4f21-9c27-7df1360e02f8\n",
            "--------------------\n",
            "Node 4:\n",
            "  Text: 2005 Dredze et al 2008 Paukkeri et al 2008 Grineva et al 2009 1264\n",
            "  ID: 9be71373-0ce8-49e2-a953-8f2b92f5d924\n",
            "--------------------\n",
            "Node 5:\n",
            "  Text: Kim and Kan 2009 reveal that syntactic features are not useful for keyphrase extraction in the pres ence of other feature types 3222 External ResourceBased Features External resourcebased features are computed based on information gathered from resources other than the training documents such as lex ical knowledge bases eg Wikipedia or the Web with the goal of improving keyphrase extrac tion performance by exploiting external knowl edge Below we give an overview of the exter nal resourcebased features that have proven use ful for keyphrase extraction Wikipediabased keyphraseness is computed as a candidates document frequency multiplied by the ratio of the number of Wikipedia articles where the candidate appears as a link to the number of articles where it appears Medelyan et al 2009 This feature is motivated by the observation that a candidate is likely to be a keyphrase if it occurs frequently as a link in Wikipedia Unlike super vised keyphraseness Wikipediabased keyphrase ness can be computed without using documents annotated with keyphrases and can work even if there is a mismatch between the training domain and the test domain Yih et al 2006 employ a feature that en codes whether a candidate keyphrase appears in the query log of a search engine exploiting the ob servation that a candidate is potentially important if it was used as a search query Terminological databases have been similarly exploited to encode the salience of candidate keyphrases in scientic papers Lopez and Romary 2010 While the aforementioned external resource based features attempt to encode how salient a candidate keyphrase is Turney 2003 proposes features that encode the semantic relatedness be tween two candidate keyphrases Noting that can didate keyphrases that are not semantically re lated to the predicted keyphrases are unlikely to be keyphrases in technical reports Turney em ploys coherence features to identify such can didate keyphrases Semantic relatedness is en coded in the coherence features as two candidate keyphrases pointwise mutual information which Turney computes by using the Web as a corpus 33 Unsupervised Approaches Existing unsupervised approaches to keyphrase extraction can be categorized into four groups 331 GraphBased Ranking Intuitively keyphrase extraction is about nding the important words and phrases from a docu ment Traditionally the importance of a candi date has often been dened in terms of how related it is to other candidates in the document Infor mally a candidate is important if it is related to 1 a large number of candidates and 2 candidates that are important Researchers have computedre latedness between candidates using cooccurrence counts Mihalcea and Tarau 2004 Matsuo and Ishizuka 2004 and semantic relatedness Grineva et al 2009 and represented the relatedness in formation collected from a document as a graph Mihalcea and Tarau 2004 Wan and Xiao 2008a Wan and Xiao 2008b Bougouin et al 2013 The basic idea behind a graphbased approach is to build a graph from the input document and rank its nodes according to their importance us ing a graphbased ranking method eg Brin and Page 1998 Each node of the graph corresponds to a candidate keyphrase from the document and an edge connects two related candidates The edge weight is proportional to the syntactic andor semantic relevance between the connected candi dates For each node each of its edges is treated as a vote from the other node connected by the edge A nodes score in the graph is dened recur sively in terms of the edges it has and the scores of the neighboring nodes The topranked candidates from the graph are then selected as keyphrases for the input document TextRank Mihalcea and Ta rau 2004 is one of the most wellknown graph based approaches to keyphrase extraction This instantiation of a graphbased approach overlooks an important aspect of keyphrase ex traction however A set of keyphrases for a doc ument should ideally cover the main topics dis cussed in it but this instantiation does not guaran tee that all the main topics will be represented by the extracted keyphrases Despite this weakness a graphbased representation of text was adopted by many approaches that propose different ways of computing the similarity between two candidates 332 TopicBased Clustering Another unsupervised approach to keyphrase extraction involves grouping the candidate keyphrases in a document into topics such that each topic is composed of all and only those candidate keyphrases that are related to that topic Grineva et al 2009 Liu et al 2009b Liu et 1265\n",
            "  ID: 762ae180-f180-413d-8959-c930589617ad\n",
            "--------------------\n",
            "Node 6:\n",
            "  Text: al 2010 There are several motivations behind this topicbased clustering approach First a keyphrase should ideally be relevant to one or more main topics discussed in a document Liu et al 2010 Liu et al 2012 Second the extracted keyphrases should be comprehensive in the sense that they should cover all the main topics in a document Liu et al 2009b Liu et al 2010 Liu et al 2012 Below we examine three representative systems that adopt this approach KeyCluster Liu et al 2009b adopt a clusteringbased approach henceforth KeyClus ter that clusters semantically similar candidates using Wikipedia and cooccurrencebased statis tics The underlying hypothesis is that each of these clusters corresponds to a topic covered in the document and selecting the candidates close to the centroid of each cluster as keyphrases ensures that the resulting set of keyphrases covers all the topics of the document While empirical results show that KeyCluster performs better than both TextRank and Hulths 2003 supervised system KeyCluster has a poten tial drawback by extracting keyphrases from each topic cluster it essentially gives each topic equal importance In practice however there could be topics that are not important and these topics should not have keyphrases representing them Topical PageRank TPR Liu et al 2010 pro pose TPR an approach that overcomes the afore mentioned weakness of KeyCluster It runs Tex tRank multiple times for a document once for each of its topics induced by a Latent Dirichlet Al location Blei et al 2003 By running TextRank once for each topic TPR ensures that the extracted keyphrases cover the main topics of the document The nal score of a candidate is computed as the sum of its scores for each of the topics weighted by the probability of that topic in that document Hence unlike KeyCluster candidates belonging to a less probable topic are given less importance TPR performs signicantly better than both tfidf and TextRank on the DUC2001 and Inspec datasets TPRs superior performance strength ens the hypothesis of using topic clustering for keyphrase extraction However though TPR is conceptually better than KeyCluster Liu et al did not compare TPR against KeyCluster CommunityCluster Grineva et al 2009 pro pose CommunityCluster a variant of the topic clustering approach to keyphrase extraction Like TPR CommunityCluster gives more weight to more important topics but unlike TPR it extracts all candidate keyphrases from an important topic assuming that a candidate that receives little focus in the text should still be extracted as a keyphrase as long as it is related to an important topic Com munityCluster yields much better recall without losing precision than extractors such as tfidf TextRank and the Yahoo term extractor 333 Simultaneous Learning Since keyphrases represent a dense summary of a document researchers hypothesized that text sum marization and keyphrase extraction can poten tially benet from each other if these tasks are per formed simultaneously Zha 2002 proposes the rst graphbased approach for simultaneous sum marization and keyphrase extraction motivated by a key observation a sentence is important if it con tains important words and important words ap pear in important sentences Wan et al 2007 ex tend Zhas work by adding two assumptions 1 an important sentence is connected to other im portant sentences and 2 an important word is linked to other important words a TextRanklike assumption Based on these assumptions Wan et al 2007 build three graphs to capture the asso ciation between the sentences S and the words W in an input document namely a SS graph a bipartite SW graph and a WW graph The weight of an edge connecting two sentence nodes in a SS graph corresponds to their content simi larity An edge weight in a SW graph denotes the words importance in the sentence it appears Fi nally an edge weight in a WW graph denotes the cooccurrence or knowledgebased similarity be tween the two connected words Once the graphs are constructed for an input document an itera tive reinforcement algorithm is applied to assign scores to each sentence and word The topscored words are used to form keyphrases The main advantage of this approach is that it combines the strengths of both Zhas approach ie bipartite SW graphs and TextRank ie W W graphs and performs better than both of them However it has a weakness like TextRank it does not ensure that the extracted keyphrases will cover all the main topics To address this problem one can employ a topic clustering algorithm on the W W graph to produce the topic clusters and then en sure that keyphrases are chosen from every main topic cluster 1266\n",
            "  ID: bd0df11f-4c76-4e16-a8b5-9a9e8e800e75\n",
            "--------------------\n",
            "Node 7:\n",
            "  Text: 334 Language Modeling Many existing approaches have a separate heuris tic module for extracting candidate keyphrases prior to keyphrase rankingextraction In contrast Tomokiyo and Hurst 2003 propose an approach henceforth LMA that combines these two steps LMA scores a candidate keyphrase based on two features namely phraseness ie the ex tent to which a word sequence can be treated as a phrase and informativeness ie the extent to which a word sequence captures the central idea of the document it appears in Intuitively a phrase that has high scores for phraseness and informa tiveness is likely to be a keyphrase These feature values are estimated using language models LMs trained on a foreground corpus and a background corpus The foreground corpus is composed of the set of documents from which keyphrases are to be extracted The background corpus is a large corpus that encodes general knowledge about the world eg the Web A unigram LM and an n gram LM are constructed for each of these two corpora Phraseness dened using the foreground LM is calculated as the loss of information in curred as a result of assuming a unigram LM ie conditional independence among the words of the phrase instead of an ngram LM ie the phrase is drawn from an ngram LM Informativeness is computed as the loss that results because of the assumption that the candidate is sampled from the background LM rather than the foreground LM The loss values are computed using Kullback Leibler divergence Candidates are ranked accord ing to the sum of these two feature values In sum LMA uses a language model rather than heuristics to identify phrases and relies on the lan guage model trained on the background corpus to determine how unique a candidate keyphrase is to the domain represented by the foreground cor pus The more unique it is to the foregrounds do main the more likely it is a keyphrase for that do main While the use of language models to iden tify phrases cannot be considered a major strength of this approach because heuristics can identify phrases fairly reliably the use of a background corpus to identify candidates that are unique to the foregrounds domain is a unique aspect of this ap proach We believe that this idea deserves further investigation as it would allow us to discover a keyphrase that is unique to the foregrounds do main but may have a low tfidf value 4 Evaluation In this section we describe metrics for evaluating keyphrase extraction systems as well as stateof theart results on commonlyused datasets 41 Evaluation Metrics Designing evaluation metrics for keyphrase ex traction is by no means an easy task To score the output of a keyphrase extraction system the typical approach which is also adopted by the SemEval2010 shared task on keyphrase extrac tion is 1 to create a mapping between the keyphrases in the gold standard and those in the system output using exact match and then 2 score the output using evaluation metrics such as precision P recall R and Fscore F Conceivably exact match is an overly strict con dition considering a predicted keyphrase incor rect even if it is a variant of a gold keyphrase For instance given the gold keyphrase neural network exact match will consider a predicted phrase incorrect even if it is an expanded version of the gold keyphrase articial neural network or one of its morphological neural networks or lexical neural net variants While morphologi cal variations can be handled using a stemmer El Beltagy and Rafea 2009 other variations may not be handled easily and reliably Human evaluation has been suggested as a pos sibility Matsuo and Ishizuka 2004 but it is time consuming and expensive For this reason re searchers have experimented with two types of automatic evaluation metrics The rst type of metrics addresses the problem with exact match These metrics reward a partial match between a predicted keyphrase and a gold keyphrase ie overlapping ngrams and are commonly used in machine translation MT and summarization evaluations They include BLEU METEOR NIST and ROUGE Nevertheless experiments show that these MT metrics only offer a partial solution to problem with exact match they can only detect a subset of the nearmisses Kim et al 2010a The second type of metrics focuses on how a system ranks its predictions Given that two sys tems A and B have the same number of correct predictions binary preference measure Bpref and mean reciprocal rank MRR Liu et al 2010 will award more credit to A than to B if the ranks of the correct predictions in As output are higher than those in Bs output Rprecision Rp is an 1267\n",
            "  ID: a67ba155-d888-46e9-8b70-bbaf197f6ae4\n",
            "--------------------\n",
            "Node 8:\n",
            "  Text: IR metric that focuses on ranking given a docu ment with n gold keyphrases it computes the pre cision of a system over its n highestranked can didates Zesch and Gurevych 2009 The motiva tion behind the design of Rp is simple a system will achieve a perfect Rp value if it ranks all the keyphrases above the nonkeyphrases 42 The State of the Art Table 2 lists the best scores on some popular evalu ation datasets and the corresponding systems For example the best Fscores on the Inspec test set the DUC2001 dataset and the SemEval2010 test set are 457 317 and 275 respectively3 Two points deserve mention First Fscores de crease as document length increases These re sults are consistent with the observation we made in Section 2 that it is more difcult to extract keyphrases correctly from longer documents Sec ond recent unsupervised approaches have rivaled their supervised counterparts in performance Mi halcea and Tarau 2004 ElBeltagy and Rafea 2009 Liu et al 2009b For example KPMiner ElBeltagy and Rafea 2010 an unsupervised system ranked third in the SemEval2010 shared task with an Fscore of 252 which is comparable to the best supervised system scoring 275 5 Analysis With the goal of providing directions for future work we identify the errors commonly made by stateoftheart keyphrase extractors below 51 Error Analysis Although a few researchers have presented a sam ple of their systems output and the corresponding gold keyphrases to show the differences between them Witten et al 1999 Nguyen and Kan 2007 Medelyan et al 2009 a systematic analysis of the major types of errors made by stateoftheart keyphrase extraction systems is missing To ll this gap we ran four keyphrase extrac tion systems on four commonlyused datasets of varying sources includingInspec abstracts Hulth 2003 DUC2001 news articles Over 2001 sci entic papers Kim et al 2010b and meeting transcripts Liu et al 2009a Specically we ran domly selected 25 documents from each of these 3A more detailed analysis of the results of the SemEval 2010 shared task and the approaches adopted by the partici pating systems can be found in Kim et al 2013 Dataset Approach and System Supervised Score P R F Abstracts Inspec Topic clustering Liu et al 2009b 350 660 457 Blogs Topic community detection Grineva et al 2009 351 615 447 News DUC 2001 Graphbased ranking for extended neighborhood Wan and Xiao 2008b 288 354 317 Papers SemEval 2010 Statistical semantic and distributional features Lopez and Romary 2010 272 278 275 Table 2 Best scores achieved on various datasets four datasets and manually analyzed the output of the four systems including tfidf the most fre quently used baseline as well as three stateofthe art keyphrase extractors of which two are unsu pervised Wan and Xiao 2008b Liu et al 2009b and one is supervised Medelyan et al 2009 Our analysis reveals that the errors fall into four major types each of which contributes signi cantly to the overall errors made by the four sys tems despite the fact that the contribution of each of these error types varies from system to system Moreover we do not observe any signicant dif ference between the types of errors made by the four systems other than the fact that the super vised system has the expected tendency to predict keyphrases seen in the training data Below we describe these four major types of errors Overgeneration errorsare a major type of pre cision error contributing to 2837 of the overall error Overgeneration errors occur when a system correctly predicts a candidate as a keyphrase be cause it contains a word that appears frequently in the associated document but at the same time er roneously outputs other candidates as keyphrases because they contain the same word Recall that for many systems it is not easy to reject a non keyphrase containing a word with a high term fre quency many unsupervised systems score a can didate by summing the score of each of its compo nent words and many supervised systems use un igrams as features to represent a candidate To be more concrete consider the news article on athlete Ben Johnson in Figure 1 where the keyphrases are boldfaced As we can see the word Olympics has a signicant presence in the document Con sequently many systems not only correctly predict Olympics as a keyphrase but also erroneously pre dict Olympic movement as a keyphrase yielding overgeneration errors Infrequency errors are a major type of re 1268\n",
            "  ID: 7ee54263-7f5f-4be0-bb32-c2331c266245\n",
            "--------------------\n",
            "Node 9:\n",
            "  Text: Canadian Ben Johnson left the Olympics today in a complete state of shock accused of cheating with drugs in the worlds fastest 100meter dash and stripped of his gold medal The prize went to American Carl Lewis Many athletes accepted the accusation that John son used a musclebuilding but dangerous and illegal an abolic steroid called stanozolol as conrmation of what they said they know has been going on in track and eld Two tests of Johnsons urine sample proved positive and his denials of drug use were rejected today This is a blow for the Olympic Games and the Olympic move ment said International Olympic Committee President Juan Antonio Samaranch Figure 1 A news article on Ben Johnson from the DUC2001 dataset The keyphrases are boldfaced call error contributing to 2427 of the overall error Infrequency errors occur when a system fails to identify a keyphrase owing to its infre quent presence in the associated document Liu et al 2011 Handling infrequency errors is a challenge because stateoftheart keyphrase ex tractors rarely predict candidates that appear only once or twice in a document In the Ben Johnson example many keyphrase extractors fail to iden tify 100meter dash and gold medal as keyphrases resulting in infrequency errors Redundancy errorsare a type of precision er ror contributing to 812 of the overall error Re dundancy errors occur when a system correctly identies a candidate as a keyphrase but at the same time outputs a semantically equivalent can didate eg its alias as a keyphrase This type of error can be attributed to a systems failure to determine that two candidates are semantically equivalent Nevertheless some researchers may argue that a system should not be penalized for re dundancy errors because the extracted candidates are in fact keyphrases In our example Olympics and Olympic games refer to the same concept so a system that predicts both of them as keyphrases commits a redundancy error Evaluation errorsare a type of recall error con tributing to 710 of the overall error An evalu ation error occurs when a system outputs a can didate that is semantically equivalent to a gold keyphrase but is considered erroneous by a scor ing program because of its failure to recognize that the predicted phrase and the corresponding gold keyphrase are semantically equivalent In other words an evaluation error is not an error made by a keyphrase extractor but an error due to the naivety of a scoring program In our exam ple while Olympics and Olympic games refer to the same concept only the former is annotated as keyphrase Hence an evaluation error occurs if a system predicts Olympic games but not Olympics as a keyphrase and the scoring program fails to identify them as semantically equivalent 52 Recommendations We recommend that background knowledge be extracted from external lexical databases eg Y AGO2 Suchanek et al 2007 Freebase Bol lacker et al 2008 BabelNet Navigli and Ponzetto 2012 to address the four types of er rors discussed above First we discuss howredundancy errorscould be addressed by using the background knowledge extracted from external databases Note that if we can identify semantically equivalent candidates then we can reduce redundancy errors The ques tion then is can background knowledge be used to help us identify semantically equivalent candi dates To answer this question note that Freebase for instance has over 40 million topics ie real world entities such as people places and things from over 70 domains eg music business ed ucation Hence before a system outputs a set of candidates as keyphrases it can use Freebase to determine whether any of them is mapped to the same Freebase topic Referring back to our run ning example both Olympics and Olympic games are mapped to a Freebase topic called Olympic games Based on this information a keyphrase ex tractor can determine that the two candidates are aliases and should output only one of them thus preventing a redundancy error Next we discuss how infrequency errors could be addressed using background knowledge A natural way to handle this problem would be to make an infrequent keyphrase frequent To ac complish this we suggest exploiting an inuen tial idea in the keyphrase extraction literature the importance of a candidate is dened in terms of how related it is to other candidates in the text see Section 331 In other words if we could relate an infrequent keyphrase to other candidates in the text we could boost its importance We believe that this could be accomplished us ing background knowledge The idea is to boost the importance of infrequent keyphrases using their frequent counterparts Consider again our running example All four systems have managed to identify Ben Johnson as a keyphrase due to its 1269\n",
            "  ID: 5f52b9c2-f671-4547-8306-345c3ea1eb5d\n",
            "--------------------\n",
            "Node 10:\n",
            "  Text: signicant presence Hence we can boost the im portance of 100meter dash and gold medal if we can relate them to Ben Johnson To do so note that Freebase maps a candi date to one or more predened topics each of which is associated with one or more types Types are similar to entity classes For instance the candidate Ben Johnson is mapped to a Freebase topic with the same name which is associated with Freebase types such as Person Athlete and Olympic athlete Types are dened for a specic domain in Freebase For instance Person Ath lete and Olympic athlete are dened in the People Sports and Olympics domains respectively Next consider the two infrequent candidates 100meter dash and gold medal 100meter dash is mapped to the topic Sprint of type Sports in the Sports do main whereas gold medal is mapped to a topic with the same name of type Olympic medal in the Olympics domain Consequently we can relate 100meter dash to Ben Johnson via the Sports do main ie they belong to different types under the same domain Additionally gold medal can be related to Ben Johnson via the Olympics domain As discussed before the relationship between two candidates is traditionally established using cooccurrence information However using co occurrence windows has its shortcomings First an adhoc window size cannot capture related can didates that are not inside the window So it is difcult to predict 100meter dash and gold medal as keyphrases they are more than 10 tokens away from frequent words such as Johnson and Olympics Second the candidates inside a window are all assumed to be related to each other but it is apparently an overly simplistic assumption There have been a few attempts to design Wikipedia based relatedness measures with promising ini tial results Grineva et al 2009 Liu et al 2009b Medelyan et al 20094 Overgeneration errorscould similarly be ad dressed using background knowledge Recall that Olympic movement is not a keyphrase in our ex ample although it includes an important word ie Olympic Freebase maps Olympic movement to a topic with the same name which is associated with a type called Musical Recording in the Mu sic domain However it does not map Olympic 4Note that it may be difcult to employ our recommen dations to address infrequency errors in informal text with uncorrelated topics because the keyphrases it contains may not be related to each other see Section 2 movement to any topic in the Olympics domain The absence of such a mapping in the Olympics domain could be used by a keyphrase extractor as a supporting evidence against predicting Olympic movement as a keyphrase Finally as mentioned beforeevaluation errors should not be considered errors made by a sys tem Nevertheless they reveal a problem with the way keyphrase extractors are currently evaluated To address this problem one possibility is to con duct human evaluations Cheaper alternatives in clude having human annotators identify semanti cally equivalent keyphrases during manual label ing and designing scoring programs that can au tomatically identify such semantic equivalences 6 Conclusion and Future Directions We have presented a survey of the state of the art in automatic keyphrase extraction While unsu pervised approaches have started to rival their su pervised counterparts in performance the task is far from being solved as reected by the fairly poor stateoftheart results on various commonly used evaluation datasets Our analysis revealed that there are at least three major challenges ahead 1 Incorporating background knowledge While much recent work has focused on algo rithmic development keyphrase extractors need to have a deeper understanding of a document in order to reach the next level of performance Such an understanding can be facilitated by the incorporation of background knowledge 2 Handling long documents While it may be possible to design better algorithms to handle the large number of candidates in long documents we believe that employing sophisticated features es pecially those that encode background knowledge will enable keyphrases and nonkeyphrases to be distinguished more easily even in the presence of a large number of candidates 3 Improving evaluation schemesTo more ac curately measure the performance of keyphrase extractors they should not be penalized for evalu ation errors We have suggested several possibili ties as to how this problem can be addressed Acknowledgments We thank the anonymous reviewers for their de tailed and insightful comments on earlier drafts of this paper This work was supported in part by NSF Grants IIS1147644 and IIS1219142 1270\n",
            "  ID: ea9c91e8-a0aa-4b8a-9208-b4416ab45ed1\n",
            "--------------------\n",
            "Node 11:\n",
            "  Text: References Ken Barker and Nadia Cornacchia 2000 Using noun phrase heads to extract document keyphrases In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of In telligence pages 4052 Gabor Berend 2011 Opinion expression mining by exploiting keyphrase extraction In Proceedings of the 5th International Joint Conference on Natural Language Processing pages 11621170 David M Blei Andrew Y Ng and Michael I Jordan 2003 Latent Dirichlet allocation Journal of Ma chine Learning Research 39931022 Kurt Bollacker Colin Evans Praveen Paritosh Tim Sturge and Jamie Taylor 2008 Freebase A col laboratively created graph database for structuring human knowledge In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data pages 12471250 Adrien Bougouin Florian Boudin and Beatrice Daille 2013 Topicrank Graphbased topic ranking for keyphrase extraction In Proceedings of the 6th In ternational Joint Conference on Natural Language Processing pages 543551 Sergey Brin and Lawrence Page 1998 The anatomy of a largescale hypertextual Web search engine Computer Networks 3017107117 Mo Chen JianTao Sun HuaJun Zeng and KwokYan Lam 2005 A practical system of keyphrase ex traction for web pages In Proceedings of the 14th ACM International Conference on Information and Knowledge Management pages 277278 Zhuoye Ding Qi Zhang and Xuanjing Huang 2011 Keyphrase extraction from online news using binary integer programming In Proceedings of the 5th In ternational Joint Conference on Natural Language Processing pages 165173 Mark Dredze Hanna M Wallach Danny Puller and Fernando Pereira 2008 Generating summary key words for emails using topics In Proceedings of the 13th International Conference on Intelligent User Interfaces pages 199206 Samhaa R ElBeltagy and Ahmed A Rafea 2009 KPMiner A keyphrase extraction system for En glish and Arabic documents Information Systems 341132144 Samhaa R ElBeltagy and Ahmed Rafea 2010 KP Miner Participation in SemEval2 In Proceedings of the 5th International Workshop on Semantic Eval uation pages 190193 Eibe Frank Gordon W Paynter Ian H Witten Carl Gutwin and Craig G NevillManning 1999 Domainspecic keyphrase extraction In Proceed ings of 16th International Joint Conference on Arti cial Intelligence pages 668673 Maria Grineva Maxim Grinev and Dmitry Lizorkin 2009 Extracting key terms from noisy and multi theme documents In Proceedings of the 18th In ternational Conference on World Wide Web pages 661670 Carl Gutwin Gordon Paynter Ian Witten Craig Nevill Manning and Eibe Frank 1999 Improving brows ing in digital libraries with keyphrase indexes De cision Support Systems 2781104 Khaled M Hammouda Diego N Matute and Mo hamed S Kamel 2005 CorePhrase Keyphrase ex traction for document clustering In Proceedings of the 4th International Conference on Machine Learn ing and Data Mining in Pattern Recognition pages 265274 Kazi Saidul Hasan and Vincent Ng 2010 Conun drums in unsupervised keyphrase extraction Mak ing sense of the stateoftheart In Proceedings of the 23rd International Conference on Computa tional Linguistics Posters pages 365373 Chong Huang Yonghong Tian Zhi Zhou Charles X Ling and Tiejun Huang 2006 Keyphrase extrac tion using semantic networks structure analysis In Proceedings of the 6th International Conference on Data Mining pages 275284 Anette Hulth and Be ata B Megyesi 2006 A study on automatically extracted keywords in text catego rization In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Compu tational Linguistics pages 537544 Anette Hulth Jussi Karlgren Anna Jonsson Henrik Bostrom and Lars Asker 2001 Automatic key word extraction using domain knowledge In Pro ceedings of the 2nd International Conference on Computational Linguistics and Intelligent Text Pro cessing pages 472482 Anette Hulth 2003 Improved automatic keyword ex traction given more linguistic knowledge In Pro ceedings of the 2003 Conference on Empirical Meth ods in Natural Language Processing pages 216 223 Anette Hulth 2004 Enhancing linguistically ori ented automatic keyword extraction In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics Short Papers pages 17 20 Xin Jiang Yunhua Hu and Hang Li 2009 A rank ing approach to keyphrase extraction In Proceed ings of the 32nd International ACM\n",
            "  ID: 8457dc60-1df9-4dfa-be84-0429243d41e4\n",
            "--------------------\n",
            "Node 12:\n",
            "  Text: A rank ing approach to keyphrase extraction In Proceed ings of the 32nd International ACM SIGIR Confer ence on Research and Development in Information Retrieval pages 756757 Daniel Kelleher and Saturnino Luz 2005 Automatic hypertext keyphrase detection In Proceedings of the 19th International Joint Conference on Articial In telligence pages\n",
            "  ID: 96fc3c3c-a44a-422b-9dba-2a41f7a9c845\n",
            "--------------------\n",
            "Node 13:\n",
            "  Text: Su Nam Kim and Timothy Baldwin 2012 Extracting keywords from multiparty live chats In Proceed ings of the 26th Pacic Asia Conference on Lan guage Information and Computation pages 199 208 Su Nam Kim and MinYen Kan 2009 Reexamining automatic keyphrase extraction approaches in scien tic articles In Proceedings of the ACLIJCNLP Workshop on Multiword Expressions pages 916 Su Nam Kim Timothy Baldwin and MinYen Kan 2010a Evaluating ngram based evaluation metrics for automatic keyphrase extraction In Proceedings of the 23rd International Conference on Computa tional Linguistics pages 572580 Su Nam Kim Olena Medelyan MinYen Kan and Timothy Baldwin 2010b SemEval2010 Task 5 Automatic keyphrase extraction from scientic arti cles In Proceedings of the 5th International Work shop on Semantic Evaluation pages 2126 Su Nam Kim Olena Medelyan MinYen Kan and Timothy Baldwin 2013 Automatic keyphrase extraction from scientic articles Language Re sources and Evaluation 473723742 Niraj Kumar and Kannan Srinathan 2008 Automatic keyphrase extraction from scientic documents us ing ngram ltration technique In Proceedings of the 8th ACM Symposium on Document Engineering pages 199208 Feifan Liu Deana Pennell Fei Liu and Yang Liu 2009a Unsupervised approaches for automatic key word extraction using meeting transcripts In Pro ceedings of Human Language Technologies The Annual Conference of the North American Chap ter of the Association for Computational Linguistics pages 620628 Zhiyuan Liu Peng Li Yabin Zheng and Maosong Sun 2009b Clustering to nd exemplar terms for keyphrase extraction In Proceedings of the 2009 Conference on Empirical Methods in Natural Lan guage Processing pages 257266 Zhiyuan Liu Wenyi Huang Yabin Zheng and Maosong Sun 2010 Automatic keyphrase extrac tion via topic decomposition In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing pages 366376 Zhiyuan Liu Xinxiong Chen Yabin Zheng and Maosong Sun 2011 Automatic keyphrase extrac tion by bridging vocabulary gap In Proceedings of the 15th Conference on Computational Natural Lan guage Learning pages 135144 Zhiyuan Liu Chen Liang and Maosong Sun 2012 Topical word trigger model for keyphrase extraction In Proceedings of the 24th International Conference on Computational Linguistics pages 17151730 Patrice Lopez and Laurent Romary 2010 HUMB Automatic key term extraction from scientic arti cles in GROBID In Proceedings of the 5th Inter national Workshop on Semantic Evaluation pages 248251 Yutaka Matsuo and Mitsuru Ishizuka 2004 Key word extraction from a single document using word cooccurrence statistical information International Journal on Articial Intelligence Tools 13 Olena Medelyan Eibe Frank and Ian H Witten 2009 Humancompetitive tagging using automatic keyphrase extraction In Proceedings of the 2009 Conference on Empirical Methods in Natural Lan guage Processing pages 13181327 Rada Mihalcea and Paul Tarau 2004 TextRank Bringing order into texts In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing pages 404411 Roberto Navigli and Simone Paolo Ponzetto 2012 BabelNet The automatic construction evaluation and application of a widecoverage multilingual se mantic network Articial Intelligence  David Newman Nagendra Koilada Jey Han Lau and Timothy Baldwin 2012 Bayesian text segmenta tion for index term identication and keyphrase ex traction In Proceedings of the 24th International Conference on Computational Linguistics pages 20772092 Thuy Dung Nguyen and MinYen Kan 2007 Keyphrase extraction in scientic publications In Proceedings of the International Conference on Asian Digital Libraries pages 317326 Chau Q Nguyen and Tuoi T Phan 2009 An ontologybased approach for key phrase extraction In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computa tional Linguistics and the 4th International Joint Conference on Natural Language Processing Short Papers pages 181184 Paul Over 2001 Introduction to DUC2001 An in trinsic evaluation of generic news text summariza tion systems In Proceedings of the 2001 Document Understanding Conference MariSanna Paukkeri Ilari T Nieminen Matti P olla and Timo Honkela 2008 A languageindependent approach to keyphrase extraction and evaluation In Proceedings of the 22nd International Conference on Computational Linguistics Companion Volume Posters pages 8386 Gerard Salton and Christopher Buckley 1988 Term weighting approaches in automatic text retrievalIn formation Processing and Management  1272\n",
            "  ID: 4dc955f5-ab1f-4cd1-8c6b-c55ed3930d93\n",
            "--------------------\n",
            "Node 14:\n",
            "  Text: Min Song IlYeol Song and Xiaohua Hu 2003 KPSpotter A exible information gainbased keyphrase extraction system In Proceedings of the 5th ACM International Workshop on Web Informa tion and Data Management pages 5053 Fabian M Suchanek Gjergji Kasneci and Gerhard Weikum 2007 Y AGO A core of semantic knowl edge In Proceedings of the 16th International World Wide Web Conference pages 697706 Takashi Tomokiyo and Matthew Hurst 2003 A lan guage model approach to keyphrase extraction In Proceedings of the ACL Workshop on Multiword Ex pressions pages 3340 Peter Turney 1999 Learning to extract keyphrases from text National Research Council Canada In stitute for Information Technology Technical Report ERB1057 Peter Turney 2000 Learning algorithms for keyphrase extraction Information Retrieval 2303336 Peter Turney 2003 Coherent keyphrase extraction via web mining In Proceedings of the 18th Inter national Joint Conference on Articial Intelligence pages 434439 Xiaojun Wan and Jianguo Xiao 2008a Col labRank Towards a collaborative approach to singledocument keyphrase extraction In Proceed ings of the 22nd International Conference on Com putational Linguistics pages 969976 Xiaojun Wan and Jianguo Xiao 2008b Single document keyphrase extraction using neighborhood knowledge In Proceedings of the 23rd AAAI Con ference on Articial Intelligence pages 855860 Xiaojun Wan Jianwu Yang and Jianguo Xiao 2007 Towards an iterative reinforcement approach for si multaneous document summarization and keyword extraction In Proceedings of the 45th Annual Meet ing of the Association of Computational Linguistics pages 552559 Chen Wang and Sujian Li 2011 CoRankBayes Bayesian learning to rank under the cotraining framework and its application in keyphrase extrac tion In Proceedings of the 20th ACM International Conference on Information and Knowledge Man agement pages 22412244 Ian H Witten Gordon W Paynter Eibe Frank Carl Gutwin and Craig G NevillManning 1999 KEA Practical automatic keyphrase extraction In Pro ceedings of the 4th ACM Conference on Digital Li braries pages 254255 YiFang Brook Wu Quanzhi Li Razvan Stefan Bot and Xin Chen 2005 Domainspecic keyphrase extraction In Proceedings of the 14th ACM Inter national Conference on Information and Knowledge Management pages 283284 WenTau Yih Joshua Goodman and Vitor R Carvalho 2006 Finding advertising keywords on web pages In Proceedings of the 15th International Conference on World Wide Web pages 213222 Wei You Dominique Fontaine and JeanPaul Barthes 2009 Automatic keyphrase extraction with a rened candidate set In Proceedings of the IEEEWICACM International Joint Conference on Web Intelligence and Intelligent Agent Technology pages 576579 Torsten Zesch and Iryna Gurevych 2009 Approxi mate matching for evaluating keyphrase extraction In Proceedings of the International Conference on Recent Advances in Natural Language Processing 2009 pages 484489 Hongyuan Zha 2002 Generic summarization and keyphrase extraction using mutual reinforcement principle and sentence clustering In Proceedings of 25th Annual International ACM SIGIR Confer ence on Research and Development in Information Retrieval pages 113120 Yongzheng Zhang Nur ZincirHeywood and Evange los Milios 2004 World Wide Web site summariza tion Web Intelligence and Agent Systems 23953 Yongzheng Zhang Nur ZincirHeywood and Evange los Milios 2005 Narrative text classication for automatic key phrase extraction in web document corpora In Proceedings of the 7th ACM Interna tional Workshop on Web Information and Data Man agement pages 5158 Xin Zhao Jing Jiang Jing He Yang Song Palakorn Achanauparp EePeng Lim and Xiaoming Li 2011 Topical keyphrase extraction from Twitter In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics Human Language Technologies pages\n",
            "  ID: d5f921c7-a544-46ed-b4f3-4a9b78b25a0c\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#seach engine"
      ],
      "metadata": {
        "id": "l_d0qGISERHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show llama_index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6QArdLiQgrO",
        "outputId": "93ee0061-a1e2-42e4-f6e4-3b99c53f6499"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: llama-index\n",
            "Version: 0.12.25\n",
            "Summary: Interface between LLMs and your data\n",
            "Home-page: https://llamaindex.ai\n",
            "Author: Jerry Liu\n",
            "Author-email: jerry@llamaindex.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama_index\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI1ZgzfKQxsn",
        "outputId": "9c545606-3bbc-4927-db43-1742fab4ac9b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.26)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.66.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama_index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama_index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.16)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama_index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama_index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama_index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama_index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama_index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.7)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama_index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama_index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama_index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama_index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama_index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama_index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, ServiceContext  # Import from llama_index.core"
      ],
      "metadata": {
        "id": "eeuFddXDQmTV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example documents to be indexed (use your actual document data)\n",
        "documents = [\n",
        "    \"Python indentation is crucial as it defines code blocks.\",\n",
        "    \"In Python, indentation is used to define the structure of control flow.\",\n",
        "    \"Python is known for its clean and readable syntax, partially due to indentation.\"\n",
        "]\n",
        "\n",
        "# Create the ServiceContext, using defaults\n",
        "service_context = ServiceContext.from_defaults()\n",
        "\n",
        "# Create the vector index from the documents\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "# Convert the index to a retriever\n",
        "retriever = index.as_retriever()\n",
        "\n",
        "# Define a custom query engine\n",
        "class CustomQueryEngine(QueryEngine):\n",
        "    def __init__(self, retriever: BaseRetriever):\n",
        "        self.retriever = retriever\n",
        "        self.synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
        "\n",
        "    def query(self, query_str: str):\n",
        "        # Retrieve relevant nodes for the query\n",
        "        nodes = self.retriever.retrieve(query_str)\n",
        "\n",
        "        # Synthesize a response\n",
        "        response = self.synthesizer.synthesize(query_str, nodes)\n",
        "\n",
        "        return response\n",
        "\n",
        "# Create the query engine instance\n",
        "query_engine = CustomQueryEngine(retriever=retriever)\n",
        "\n",
        "# Example search query\n",
        "query = \"What is Python indentation?\"\n",
        "\n",
        "# Run the query and get the response\n",
        "response = query_engine.query(query)\n",
        "\n",
        "# Output the response\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "CrXgekhiEdqj",
        "outputId": "11390c23-f1c0-4489-b582-cf02085d4bdd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ServiceContext is deprecated. Use llama_index.settings.Settings instead, or pass in modules to local functions/methods/interfaces.\nSee the docs for updated usage/migration: \nhttps://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-8fea5419f732>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create the ServiceContext, using defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mservice_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create the vector index from the documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/service_context.py\u001b[0m in \u001b[0;36mfrom_defaults\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;34m\"ServiceContext is deprecated. Use llama_index.settings.Settings instead, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m\"or pass in modules to local functions/methods/interfaces.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ServiceContext is deprecated. Use llama_index.settings.Settings instead, or pass in modules to local functions/methods/interfaces.\nSee the docs for updated usage/migration: \nhttps://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YCK8GjHBDiQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}